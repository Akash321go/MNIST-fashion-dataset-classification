{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Python - MNIST Fashion With Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lots of Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build predictive models in Python we use a set of libraries that are imported here. In particular **pandas** and **sklearn** are particularly important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import display, HTML, Image\n",
    "import io\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from random import randint\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "\n",
    "%matplotlib inline\n",
    "#%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a data sampling rate for speeding up testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sampling_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the number of folds for all grid searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_folds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a dictionary to store simple model perofrmance comparions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test_accuracy_comparisons = dict()\n",
    "model_valid_accuracy_comparisons = dict()\n",
    "model_tuned_params_list = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Partition Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52171</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59969</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "52171      1       0       0       0       0       0       0       0       0   \n",
       "10420      5       0       0       0       0       0       0       0       0   \n",
       "6477       7       0       0       0       0       0       0       0       0   \n",
       "59969      1       0       0       0       0       0       0       0       0   \n",
       "4948       7       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "52171       0    ...          148         0         0         0         0   \n",
       "10420       0    ...            0         0         0         0         0   \n",
       "6477        0    ...            0         0         0         0         0   \n",
       "59969       0    ...           10         0         0         0         0   \n",
       "4948        0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "52171         0         0         0         0         0  \n",
       "10420         0         0         0         0         0  \n",
       "6477          0         0         0         0         0  \n",
       "59969         0         0         0         0         0  \n",
       "4948          0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv('fashion-mnist_train.csv')\n",
    "dataset = dataset.sample(frac=data_sampling_rate) #take a sample from the dataset so everyhting runs smoothly\n",
    "num_classes = 10\n",
    "classes = {0: \"T-shirt/top\", 1:\"Trouser\", 2: \"Pullover\", 3:\"Dress\", 4:\"Coat\", 5:\"Sandal\", 6:\"Shirt\", 7:\"Sneaker\", 8:\"Bag\", 9:\"Ankle boot\"}\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the distribution of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].value_counts()\n",
    "dataset.select_dtypes(include=[np.object]).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.00000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.463500</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>2.231167</td>\n",
       "      <td>6.033833</td>\n",
       "      <td>...</td>\n",
       "      <td>35.217000</td>\n",
       "      <td>23.311333</td>\n",
       "      <td>16.442333</td>\n",
       "      <td>17.110833</td>\n",
       "      <td>21.545167</td>\n",
       "      <td>17.133167</td>\n",
       "      <td>8.312833</td>\n",
       "      <td>2.946333</td>\n",
       "      <td>0.903500</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872231</td>\n",
       "      <td>0.180739</td>\n",
       "      <td>0.164775</td>\n",
       "      <td>1.077131</td>\n",
       "      <td>3.300159</td>\n",
       "      <td>4.535616</td>\n",
       "      <td>7.04391</td>\n",
       "      <td>9.002254</td>\n",
       "      <td>14.260445</td>\n",
       "      <td>24.571759</td>\n",
       "      <td>...</td>\n",
       "      <td>58.035586</td>\n",
       "      <td>48.936209</td>\n",
       "      <td>42.140004</td>\n",
       "      <td>42.925773</td>\n",
       "      <td>50.177953</td>\n",
       "      <td>44.378670</td>\n",
       "      <td>29.148681</td>\n",
       "      <td>18.244733</td>\n",
       "      <td>9.513654</td>\n",
       "      <td>1.573048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label       pixel1       pixel2       pixel3       pixel4  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      4.463500     0.002333     0.004500     0.038500     0.137000   \n",
       "std       2.872231     0.180739     0.164775     1.077131     3.300159   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       9.000000    14.000000    10.000000    78.000000   150.000000   \n",
       "\n",
       "            pixel5      pixel6       pixel7       pixel8       pixel9  \\\n",
       "count  6000.000000  6000.00000  6000.000000  6000.000000  6000.000000   \n",
       "mean      0.244500     0.46950     0.860000     2.231167     6.033833   \n",
       "std       4.535616     7.04391     9.002254    14.260445    24.571759   \n",
       "min       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "max     217.000000   188.00000   213.000000   218.000000   226.000000   \n",
       "\n",
       "          ...          pixel775     pixel776     pixel777     pixel778  \\\n",
       "count     ...       6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean      ...         35.217000    23.311333    16.442333    17.110833   \n",
       "std       ...         58.035586    48.936209    42.140004    42.925773   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...         60.000000     7.000000     0.000000     0.000000   \n",
       "max       ...        253.000000   250.000000   254.000000   247.000000   \n",
       "\n",
       "          pixel779     pixel780     pixel781     pixel782     pixel783  \\\n",
       "count  6000.000000  6000.000000  6000.000000  6000.000000  6000.000000   \n",
       "mean     21.545167    17.133167     8.312833     2.946333     0.903500   \n",
       "std      50.177953    44.378670    29.148681    18.244733     9.513654   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max     255.000000   245.000000   226.000000   238.000000   199.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  6000.000000  \n",
       "mean      0.060000  \n",
       "std       1.573048  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max      56.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(dataset.select_dtypes(include=[np.number]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.number]).describe())\n",
    "if(dataset.select_dtypes(include=[np.object]).shape[1] > 0):\n",
    "    display(dataset.select_dtypes(include=[np.object]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values\n",
      "label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "pixel5      0\n",
      "pixel6      0\n",
      "pixel7      0\n",
      "pixel8      0\n",
      "pixel9      0\n",
      "pixel10     0\n",
      "pixel11     0\n",
      "pixel12     0\n",
      "pixel13     0\n",
      "pixel14     0\n",
      "pixel15     0\n",
      "pixel16     0\n",
      "pixel17     0\n",
      "pixel18     0\n",
      "pixel19     0\n",
      "pixel20     0\n",
      "pixel21     0\n",
      "pixel22     0\n",
      "pixel23     0\n",
      "pixel24     0\n",
      "pixel25     0\n",
      "pixel26     0\n",
      "pixel27     0\n",
      "pixel28     0\n",
      "pixel29     0\n",
      "           ..\n",
      "pixel755    0\n",
      "pixel756    0\n",
      "pixel757    0\n",
      "pixel758    0\n",
      "pixel759    0\n",
      "pixel760    0\n",
      "pixel761    0\n",
      "pixel762    0\n",
      "pixel763    0\n",
      "pixel764    0\n",
      "pixel765    0\n",
      "pixel766    0\n",
      "pixel767    0\n",
      "pixel768    0\n",
      "pixel769    0\n",
      "pixel770    0\n",
      "pixel771    0\n",
      "pixel772    0\n",
      "pixel773    0\n",
      "pixel774    0\n",
      "pixel775    0\n",
      "pixel776    0\n",
      "pixel777    0\n",
      "pixel778    0\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for presence of missing values\n",
    "print(\"Missing Values\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the descriptive features we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dataset[dataset.columns[1:]]\n",
    "Y = np.array(dataset[\"label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4566 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3149 ]  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoP4fyDu2+QL/hSMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5542 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3195 ]  T-shirt/top\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5730 ]  Bag\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3988 ]  Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1511 ]  Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nivADmfp/EKX9q+2bOzMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2815 ]  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFdFJREFUeJzt3WuMnOV1B/D/2dn77PqyVy++LRhD\nTCiYsnWhJgmXmpIokkklEK5CHDWKqQRqkPKhFFUNVRsJpSUJH0oip7gYGm4VODiCpFhOIhfSEhZj\nwK7Bds0aX9Z7sb3rvc7uzJ5+2HG6MfucZ5h3buvn/5Ms786Z532ffWfOzOye5yKqCiIKT1mxO0BE\nxcHkJwoUk58oUEx+okAx+YkCxeQnChSTnyhQTH6iQDH5iQJVXsiTNTU16fLl7YU85QVhKJE04x+e\nHHLGUqmUffCpKc/ZI44AnXKfP1ZdYzati1eZ8WTK7vvShe7j11TEzLZR+a6a5Om8R450ob+/P6PD\nR0p+EbkNwKMAYgD+RVUftu6/fHk7Xn+jM8opg/TawX4zvuEfdzpjw4PD9sHHR+14yn7hgXpePMbd\n559/2afNpjdcf7EZ7x0YM+Pf/9OrnLErlswz20Y1NWWnf1lZftJ/7R92ZHzfrD/2i0gMwD8D+DyA\nKwBsEJErsj0eERVWlN/51wA4pKqHVXUCwLMA1uemW0SUb1GSfzGAozO+P5a+7XeIyCYR6RSRzr7+\nvginI6JcipL8s/3S8rFfdFR1s6p2qGpHc1NzhNMRUS5FSf5jAJbO+H4JgBPRukNEhRIl+d8EsFJE\nLhaRSgB3Adiem24RUb5lXepT1aSI3AfgPzBd6tuiqvty1rNP3h8zLhKttGKVbp7afcRs+8iL75vx\no+94LluswgzPX3KRO9Y432w7ctZ+CiQnPKU+32WNL3CGxsfGzaav7rCvy5Snzn/zW13OWPvKNrPt\nD798rRlf3e7+uQB/Kc96vkZ9rmYqUp1fVV8B8EqO+kJEBcThvUSBYvITBYrJTxQoJj9RoJj8RIFi\n8hMFqqDz+aPKZ230z5/ZY8Z3/PIDZ2y4p9dsW15vTx+tabVrzj7JSU8t3lBVY8+Zr5tfZ8Z9193q\n25RnLYGpMjuu5dmP7Tiw1x6bcdO99vPhrq+uM+M/uMM9nRiw+5bvMSvn8J2fKFBMfqJAMfmJAsXk\nJwoUk58oUEx+okDNqVJfyphWWx6zyx9/+3N3qQ4AfvryO2Y8Xh93xuoXtZptfXylOl/pZ3TIvQKv\nelaR9ZX6RgZHzHh5RfZPId+y4uqJV8Xtpb+t61bjaVvRYJdnn33212b8U4vczxcA+MZnVjhjnocM\nnqd6xvjOTxQoJj9RoJj8RIFi8hMFislPFCgmP1GgmPxEgZpTdf7yWPavVa/v7zHj8zx1Xate7qtX\n++r4ja0NZrzds0z04GDCGVveVm+29e10G/Nc8+PHz5rxmhr3suNHP7Qfk09fvcyM7/7vg2bcGsPg\nmxbri8cb7MfkqZ2HzbhV54/laQff8/GdnyhQTH6iQDH5iQLF5CcKFJOfKFBMfqJAMfmJAhWpzi8i\nXQCGAKQAJFW1IxedysbYhF1r7+mx56X75r0nxty19Nr6WrPtQP+AfW7PfH2fRMI9jqCm0n6Ij3Sd\nMePXX7vEjPf12dd1iTHOYMGCarPtpRfZYy/k+pVmvPPXB9znbrLr9L5lxcvL7eva3ztoxkfG3Y9Z\nvLoww29ycZabVLU/B8chogLix36iQEVNfgXwqoi8JSKbctEhIiqMqB/716rqCRFpAbBDRN5X1V0z\n75B+UdgEAEuX2WO1iahwIr3zq+qJ9P+9ALYBWDPLfTaraoeqdjQ3NUc5HRHlUNbJLyJxEak/9zWA\nWwHszVXHiCi/onzsbwWwLT31sRzA06r685z0iojyLuvkV9XDAK7OYV8i6RkcN+Njo3ZcPHOox0bc\n896r43a92re2/URi0oy3t9hz8kdGJpyxqsqY2faWP2o340Njdt98YxTKjOvassBeO/+ln+0z45+5\n4VLPud0fbGPl9nVJjtlrMJR51jlITtjtTwy4n48rF9nboucKS31EgWLyEwWKyU8UKCY/UaCY/ESB\nYvITBWpOLd1tOTrg3qYaABKj7im5AFBVa29VrWPuqaupSc+y3xGn7B48bk8PnV/vLjX+b7e9tPbZ\ns/Z1qa11L70NAK2tdlmqqtz9/rKs0Z4KvWhJoxmf8lxXa/lt35TdqZQd95X6fI/5qRH3dV8JlvqI\nKI+Y/ESBYvITBYrJTxQoJj9RoJj8RIFi8hMF6oKp8+/rGzLjvrqrb0tmVLpr6VFrxm0XzTfjp07Z\nYxhO97t/dl89+rprl5rxgVH3dGEA2PvucTM+2ONe2Pn6W64y2y5fYl+Xzt3HzLhvqrUl6tgMX/vd\nJ91jN65bYY9vyBW+8xMFislPFCgmP1GgmPxEgWLyEwWKyU8UKCY/UaAumDp/1xl7Xrqv7urbohvi\nfp2sqLLnvI8O2XV6a+ltAFjs2ar6s9csdsYOdNtrAfxq10Ez7vvZ/mbjtWb8sZfdx79q+UKz7duH\nT5txeIZmWHyPt2/shm9ciC/e+ZGxzsJas2nO8J2fKFBMfqJAMfmJAsXkJwoUk58oUEx+okAx+YkC\n5a3zi8gWAF8E0KuqV6ZvawDwHIB2AF0A7lTVM/nrpt8HJ+z16X11W+/8bXW399WMU4OnzPim2z5n\nxh/dtt+M7+7scsbi8+Jm23HP1uXNbXYtvrm20oxb6/5v+8Uhs208bu+l4Nv63FpHIWqd3veY+7YA\nP3LSfr4WQibv/E8AuO282x4AsFNVVwLYmf6eiOYQb/Kr6i4A5w+1Wg9ga/rrrQBuz3G/iCjPsv2d\nv1VVuwEg/X9L7rpERIWQ9z/4icgmEekUkc6+/r58n46IMpRt8veISBsApP/vdd1RVTeraoeqdjQ3\nNWd5OiLKtWyTfzuAjemvNwJ4KTfdIaJC8Sa/iDwD4L8AXC4ix0TkawAeBrBORA4CWJf+nojmEG+d\nX1U3OEK35LgvkfT0jZhx77r8PsZ8/smJSbNp2bwGMx6vtF+DB/oHzHjLRe513i9fYZ9bfq/NjH+5\n4yIz/m+dJ8z4Jcba+4tb7X3olzTaYxSe3va2Ga+tr3XGysrsa+7b7yCVSplx3/Otr89e46EQOMKP\nKFBMfqJAMfmJAsXkJwoUk58oUEx+okBdMEt3n+qPVurzbaNtTen1Hds3vXOBZ3nssX73NtcAcNXN\nn3IfO25PuT3UbU8t3ddrX9fW+TVm/OZLFzhjteX20+/bL79vxhc0uY8NAGMjY+6g55mfnEia8fJK\n+wC+6cZnzwzbHSgAvvMTBYrJTxQoJj9RoJj8RIFi8hMFislPFCgmP1GgLpg6/9DAkBn3LtVclv2U\nX19NNzlp14wf29Vlxlsvu8SM/2aPe1ptTY09hqCpyZ42+8TPDpjxiYS9vfjr77in7ba02OceHbWn\nSvuWHbfGV3i3ZPfwtfdNGa6pr450/lzgOz9RoJj8RIFi8hMFislPFCgmP1GgmPxEgWLyEwXqgqnz\n1y+sN+OjQ/ZSyd66b8I9N9w3xmDV1Reb8b9et9KM//veHjN+4rT7Z9v1K3tOfM9x+ylgLQsOAJs3\nrTHjG76z0xmrqrLP/cw915nxW/9hhxm3xnZUVNvjH4YH7fn25WWe1PEMG0mMu8dHDI/b40LqqnOT\ntnznJwoUk58oUEx+okAx+YkCxeQnChSTnyhQTH6iQHkLhiKyBcAXAfSq6pXp2x4C8HUAfem7Paiq\nr+Srk+ckjbX1JxP23O9YzF47P5m0a6tIuNev16l5ZtM/WNVixmti9sOw/yN7i+6lLe458w/9xQ1m\n20eee8eMNzba6/Jfu2yhGf+z9Vc7Y19Y2WS2/bsd9loCI2ftPQXi8+31Aiyq9rgP3z4P3n0gDBPJ\n7Nt+Epm88z8B4LZZbv+eqq5O/8t74hNRbnmTX1V3AThdgL4QUQFF+Z3/PhF5V0S2iIj92Y+ISk62\nyf8DACsArAbQDeAR1x1FZJOIdIpIZ19/n+tuRFRgWSW/qvaoakpVpwD8CIBzdoeqblbVDlXtaG5q\nzrafRJRjWSW/iLTN+PZLAPbmpjtEVCiZlPqeAXAjgCYROQbgWwBuFJHVABRAF4B78thHIsoDb/Kr\n6oZZbn48D33xOjPiruVHqasCGcznT7nHATQusue8P/3CW2b82Z+8bcYTJ4+b8cMrL3PG7l97s9n2\n7z3rHOz+xREzfodnXvyhQ/3OWMyzV8JPt9vXpWFRgxmP8pzw7bXgUxO3x0ecPuAewzCS+BOzbUNd\nZVZ9Oh9H+BEFislPFCgmP1GgmPxEgWLyEwWKyU8UqDm1dPekUboZPLjfbDv/slXRTq7uc/u2966u\ntbdj9m3xXbGs3W5f6W7/l8/vMdsmJ+ySVtsqdxkRAH7zmj3ttqLKXQr84dbXzbYNrXYpLwrflu3w\n7eAdbYdv09hEKn8Hn4Hv/ESBYvITBYrJTxQoJj9RoJj8RIFi8hMFislPFKg5Vec365/JhNnWV9ed\nmvJM/zzrXoLMd2zfMtC+6aO+cQAjg+4lrPf12Guvzmu0lx33bW1et8C9bDgAxMrdS6bPb5xvtk2M\nRXtMrevurfNPurfQBoCUZ2yH7zG3lNLS3UR0AWLyEwWKyU8UKCY/UaCY/ESBYvITBYrJTxSoOVXn\nn0wZtdOpaHOgvUs1G9tox2L2a6hvWfBYpb19uK9mbI0DKPP0LfKS5xG2sp6csLdV9588Ytxsa18X\nTUWcc1/mfsyHEtGWDc+4CwU5CxGVHCY/UaCY/ESBYvITBYrJTxQoJj9RoJj8RIHy1vlFZCmAJwEs\nAjAFYLOqPioiDQCeA9AOoAvAnap6Jn9dBc6OZ18X9s3f9tb5a9zz3id9bT1Tx3219rKy7F+jfXX4\nVNKuV/vGCUSZU+87t6/v+bwuUm1vsa2jw1mfG4A5buTk6Fi0Y2cok6uXBPBNVV0F4DoA94rIFQAe\nALBTVVcC2Jn+nojmCG/yq2q3qu5Ofz0EYD+AxQDWA9iavttWALfnq5NElHuf6HOTiLQDuAbAGwBa\nVbUbmH6BANCS684RUf5knPwiUgfgBQD3q+rZT9Buk4h0ikhnX797HTwiKqyMkl9EKjCd+D9W1RfT\nN/eISFs63gagd7a2qrpZVTtUtaO5qTkXfSaiHPAmv0z/OfdxAPtV9bszQtsBbEx/vRHAS7nvHhHl\nSyZTetcCuBvAeyJybr/nBwE8DOB5EfkagI8A3JGfLv6/0+PGUs6e0o23tOMrWVW6Sz/eZaA9oizz\nnHeerqnnDpGuje/cvunExnLsvvJqZVWlGU8M2OU471Lwhv7RiFOdM+RNflV9De5K9S257Q4RFQpH\n+BEFislPFCgmP1GgmPxEgWLyEwWKyU8UqDm1dPexoXF3sCputvVN//Qtr41J97mjTj31TW2NtL24\n58eSmH3slGeJal/foky79dXKyyK8dyWsMSMAaursKb2J454tvD2PKWIVztDxQfvYucJ3fqJAMfmJ\nAsXkJwoUk58oUEx+okAx+YkCxeQnCtScqvMPJ9x134q25WZbX921vNK+FKkW9/ETY3bN2DcOIFYe\nbYvuKNtsR12aO598P1eUdRBGh0bN+KWrlpjxgd5FkY4fb2o044XAd36iQDH5iQLF5CcKFJOfKFBM\nfqJAMfmJAsXkJwrUnKrz7znq3iWsstpeZz2ZtLfRblls7yZUW+s+/qF3D5lt65sazPjkhL1Oeyxm\njwOwavGR1gLIgG8dhClxH9/3mJWLZ+yFb+xGhbv98IC9xXZTY60Zr6m3148YGxox41Lmflw6Pzxt\nts0VvvMTBYrJTxQoJj9RoJj8RIFi8hMFislPFCgmP1GgvHV+EVkK4EkAiwBMAdisqo+KyEMAvg6g\nL33XB1X1lXx1FACOnHTX+Ue6u+3G5XZN2Td3fLSmyhmrqqsz20Zdt98Xt/aSt+rJmRzbN07Ad3xr\n34CJhGd9es90fd9aBFa8qtb9eAJAhefYyUl73AgG+8zwZNy9L0B1hT2uI1cyGeSTBPBNVd0tIvUA\n3hKRHenY91T1n/LXPSLKF2/yq2o3gO7010Mish/A4nx3jIjy6xP9zi8i7QCuAfBG+qb7RORdEdki\nIgsdbTaJSKeIdPb12x+FiKhwMk5+EakD8AKA+1X1LIAfAFgBYDWmPxk8Mls7Vd2sqh2q2tHcZI+f\nJ6LCySj5RaQC04n/Y1V9EQBUtUdVU6o6BeBHANbkr5tElGve5JfpP/c+DmC/qn53xu1tM+72JQB7\nc989IsqXTP7avxbA3QDeE5E96dseBLBBRFZjuiDTBeCevPRwhn/9Socz9va6FWbbMU9Ja16le8tk\nALj7vsecseqLV5ltfVN2vdORPWUlq9zmK9VZ016BDJYV90zptcp5UacTTxlLufuOP5mwH5P9B/rN\neO9TXzHjp4btMmZtpfu61hixXMrkr/2vAZjtGZTXmj4R5RdH+BEFislPFCgmP1GgmPxEgWLyEwWK\nyU8UqDm1dHd7s3u5ZCuWC5f/8U3O2PGP7JqwrxaeGLW3+J610DpDcsIzvdTg25q8EvYYBN8YBms6\nc3Vttdk2ytbjAFBT5542G/csvX3jmqWRzt1YZ1+3UsB3fqJAMfmJAsXkJwoUk58oUEx+okAx+YkC\nxeQnCpSoetZHzuXJRPoAHJlxUxMAu0hePKXat1LtF8C+ZSuXfVuuqhmtl1fQ5P/YyUU6VdW9QkcR\nlWrfSrVfAPuWrWL1jR/7iQLF5CcKVLGTf3ORz28p1b6Var8A9i1bRelbUX/nJ6LiKfY7PxEVSVGS\nX0RuE5EPROSQiDxQjD64iEiXiLwnIntEpLPIfdkiIr0isnfGbQ0iskNEDqb/n3WbtCL17SEROZ6+\ndntE5AtF6ttSEfmliOwXkX0i8o307UW9dka/inLdCv6xX0RiAA4AWAfgGIA3AWxQ1f8paEccRKQL\nQIeqFr0mLCKfBTAM4ElVvTJ923cAnFbVh9MvnAtV9a9KpG8PARgu9s7N6Q1l2mbuLA3gdgBfRRGv\nndGvO1GE61aMd/41AA6p6mFVnQDwLID1RehHyVPVXQBOn3fzegBb019vxfSTp+AcfSsJqtqtqrvT\nXw8BOLezdFGvndGvoihG8i8GcHTG98dQWlt+K4BXReQtEdlU7M7MojW9bfq57dNbityf83l3bi6k\n83aWLplrl82O17lWjOSfbVGqUio5rFXV3wfweQD3pj/eUmYy2rm5UGbZWbokZLvjda4VI/mPAZi5\nQNoSACeK0I9ZqeqJ9P+9ALah9HYf7jm3SWr6/94i9+e3Smnn5tl2lkYJXLtS2vG6GMn/JoCVInKx\niFQCuAvA9iL042NEJJ7+QwxEJA7gVpTe7sPbAWxMf70RwEtF7MvvKJWdm107S6PI167UdrwuyiCf\ndCnj+wBiALao6rcL3olZiMglmH63B6ZXNn66mH0TkWcA3IjpWV89AL4F4CcAngewDMBHAO5Q1YL/\n4c3Rtxsx/dH1tzs3n/sdu8B9uwHAfwJ4D8C5JYAfxPTv10W7dka/NqAI140j/IgCxRF+RIFi8hMF\nislPFCgmP1GgmPxEgWLyEwWKyU8UKCY/UaD+DwC5zjSldOyDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1338 ]  Shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGH6iQDH8RIFi+IkCxfATBYrhJwrU/wPX3ylrei56bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a sample of images from the dataset\n",
    "for i in range(0, 9):\n",
    "    i_rand = randint(0, X.shape[0])\n",
    "\n",
    "    print(\"[\", i_rand, \"] \", classes[Y[i_rand]])\n",
    "    two_d = (X.iloc[i_rand].values.reshape(28, 28))\n",
    "    pyplot.imshow(two_d, cmap='Blues')\n",
    "    pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise the data (important for some models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract some higher level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52171</th>\n",
       "      <td>0.284289</td>\n",
       "      <td>0.279252</td>\n",
       "      <td>0.289326</td>\n",
       "      <td>0.254482</td>\n",
       "      <td>0.266246</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.264146</td>\n",
       "      <td>0.271989</td>\n",
       "      <td>0.273669</td>\n",
       "      <td>0.274790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297059</td>\n",
       "      <td>0.298459</td>\n",
       "      <td>0.303641</td>\n",
       "      <td>0.302241</td>\n",
       "      <td>0.302101</td>\n",
       "      <td>0.303501</td>\n",
       "      <td>0.298599</td>\n",
       "      <td>0.322549</td>\n",
       "      <td>0.151401</td>\n",
       "      <td>0.265306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>0.065536</td>\n",
       "      <td>0.047199</td>\n",
       "      <td>0.083874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>0.250925</td>\n",
       "      <td>0.177281</td>\n",
       "      <td>0.324570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>0.087955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597059</td>\n",
       "      <td>0.308824</td>\n",
       "      <td>0.437535</td>\n",
       "      <td>0.204482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.186224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59969</th>\n",
       "      <td>0.205062</td>\n",
       "      <td>0.241807</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.312605</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>0.268067</td>\n",
       "      <td>0.284454</td>\n",
       "      <td>0.296218</td>\n",
       "      <td>0.281092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165266</td>\n",
       "      <td>0.174930</td>\n",
       "      <td>0.179692</td>\n",
       "      <td>0.180252</td>\n",
       "      <td>0.179272</td>\n",
       "      <td>0.179552</td>\n",
       "      <td>0.168908</td>\n",
       "      <td>0.197759</td>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.186224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>0.142382</td>\n",
       "      <td>0.094848</td>\n",
       "      <td>0.189916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027031</td>\n",
       "      <td>0.041317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>0.267917</td>\n",
       "      <td>0.270188</td>\n",
       "      <td>0.265646</td>\n",
       "      <td>0.114006</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.178852</td>\n",
       "      <td>0.197759</td>\n",
       "      <td>0.167647</td>\n",
       "      <td>0.270168</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297059</td>\n",
       "      <td>0.293557</td>\n",
       "      <td>0.290056</td>\n",
       "      <td>0.289636</td>\n",
       "      <td>0.300280</td>\n",
       "      <td>0.321709</td>\n",
       "      <td>0.242017</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.091597</td>\n",
       "      <td>0.028061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26098</th>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.424540</td>\n",
       "      <td>0.083613</td>\n",
       "      <td>0.218207</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.493277</td>\n",
       "      <td>0.557283</td>\n",
       "      <td>0.547479</td>\n",
       "      <td>0.554762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587955</td>\n",
       "      <td>0.589916</td>\n",
       "      <td>0.586695</td>\n",
       "      <td>0.613585</td>\n",
       "      <td>0.544258</td>\n",
       "      <td>0.029132</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.395408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11154</th>\n",
       "      <td>0.277981</td>\n",
       "      <td>0.260724</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.227591</td>\n",
       "      <td>0.252241</td>\n",
       "      <td>0.282213</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.269048</td>\n",
       "      <td>0.253081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316527</td>\n",
       "      <td>0.320028</td>\n",
       "      <td>0.331513</td>\n",
       "      <td>0.338515</td>\n",
       "      <td>0.366807</td>\n",
       "      <td>0.256583</td>\n",
       "      <td>0.246919</td>\n",
       "      <td>0.279552</td>\n",
       "      <td>0.155182</td>\n",
       "      <td>0.091837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.366186</td>\n",
       "      <td>0.334144</td>\n",
       "      <td>0.398229</td>\n",
       "      <td>0.053081</td>\n",
       "      <td>0.156162</td>\n",
       "      <td>0.206583</td>\n",
       "      <td>0.259384</td>\n",
       "      <td>0.329692</td>\n",
       "      <td>0.400140</td>\n",
       "      <td>0.431232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437255</td>\n",
       "      <td>0.437815</td>\n",
       "      <td>0.419888</td>\n",
       "      <td>0.356162</td>\n",
       "      <td>0.352801</td>\n",
       "      <td>0.348599</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.343978</td>\n",
       "      <td>0.326050</td>\n",
       "      <td>0.311224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>0.540786</td>\n",
       "      <td>0.596349</td>\n",
       "      <td>0.485224</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.270168</td>\n",
       "      <td>0.591877</td>\n",
       "      <td>0.611064</td>\n",
       "      <td>0.633473</td>\n",
       "      <td>0.646359</td>\n",
       "      <td>0.662745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702521</td>\n",
       "      <td>0.511064</td>\n",
       "      <td>0.491176</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.379412</td>\n",
       "      <td>0.368067</td>\n",
       "      <td>0.064566</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>0.492347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "52171        0.284289            0.279252               0.289326   0.254482   \n",
       "10420        0.065536            0.047199               0.083874   0.000000   \n",
       "6477         0.250925            0.177281               0.324570   0.000000   \n",
       "59969        0.205062            0.241807               0.168317   0.139776   \n",
       "4948         0.142382            0.094848               0.189916   0.000000   \n",
       "27748        0.267917            0.270188               0.265646   0.114006   \n",
       "26098        0.464286            0.504032               0.424540   0.083613   \n",
       "11154        0.277981            0.260724               0.295238   0.102381   \n",
       "34           0.366186            0.334144               0.398229   0.053081   \n",
       "10139        0.540786            0.596349               0.485224   0.025070   \n",
       "\n",
       "       row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6  \\\n",
       "52171   0.266246   0.270588   0.264146   0.271989   0.273669   0.274790   \n",
       "10420   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "6477    0.000000   0.000000   0.000000   0.000000   0.022549   0.087955   \n",
       "59969   0.312605   0.247899   0.268067   0.284454   0.296218   0.281092   \n",
       "4948    0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "27748   0.274510   0.178852   0.197759   0.167647   0.270168   0.338235   \n",
       "26098   0.218207   0.345518   0.493277   0.557283   0.547479   0.554762   \n",
       "11154   0.227591   0.252241   0.282213   0.299300   0.269048   0.253081   \n",
       "34      0.156162   0.206583   0.259384   0.329692   0.400140   0.431232   \n",
       "10139   0.270168   0.591877   0.611064   0.633473   0.646359   0.662745   \n",
       "\n",
       "         ...     row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  \\\n",
       "52171    ...       0.297059    0.298459    0.303641    0.302241    0.302101   \n",
       "10420    ...       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "6477     ...       0.597059    0.308824    0.437535    0.204482    0.000000   \n",
       "59969    ...       0.165266    0.174930    0.179692    0.180252    0.179272   \n",
       "4948     ...       0.027031    0.041317    0.000000    0.000000    0.000000   \n",
       "27748    ...       0.297059    0.293557    0.290056    0.289636    0.300280   \n",
       "26098    ...       0.587955    0.589916    0.586695    0.613585    0.544258   \n",
       "11154    ...       0.316527    0.320028    0.331513    0.338515    0.366807   \n",
       "34       ...       0.437255    0.437815    0.419888    0.356162    0.352801   \n",
       "10139    ...       0.702521    0.511064    0.491176    0.459244    0.379412   \n",
       "\n",
       "       row_sum_24  row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "52171    0.303501    0.298599    0.322549    0.151401  0.265306  \n",
       "10420    0.000000    0.000000    0.000000    0.000000  0.017857  \n",
       "6477     0.000000    0.000000    0.000000    0.000000  0.186224  \n",
       "59969    0.179552    0.168908    0.197759    0.089216  0.186224  \n",
       "4948     0.000000    0.000000    0.000000    0.000000  0.096939  \n",
       "27748    0.321709    0.242017    0.102941    0.091597  0.028061  \n",
       "26098    0.029132    0.005322    0.024230    0.006583  0.395408  \n",
       "11154    0.256583    0.246919    0.279552    0.155182  0.091837  \n",
       "34       0.348599    0.345518    0.343978    0.326050  0.311224  \n",
       "10139    0.368067    0.064566    0.078571    0.104062  0.492347  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engineered_features = pd.DataFrame()\n",
    "\n",
    "# Calcualte percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features['percent_filled'] = percent_filled\n",
    "engineered_features['percent_filled_top'] = percent_filled_top\n",
    "engineered_features['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(X.iloc[:, 0:392]))\n",
    "\n",
    "s2 = np.round(np.array(X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*14)\n",
    "\n",
    "engineered_features['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729591836734694"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_features['symmetry'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = engineered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a **training set**, a **vaidation set**, and a **test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_plus_valid, X_test, y_train_plus_valid, y_test \\\n",
    "    = train_test_split(X, Y, random_state=0, \\\n",
    "                                    train_size = 0.7)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid \\\n",
    "    = train_test_split(X_train_plus_valid, \\\n",
    "                                        y_train_plus_valid, \\\n",
    "                                        random_state=0, \\\n",
    "                                        train_size = 0.5/0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Very Simple Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00       283\n",
      "          1       1.00      1.00      1.00       305\n",
      "          2       1.00      1.00      1.00       311\n",
      "          3       1.00      1.00      1.00       319\n",
      "          4       1.00      1.00      1.00       293\n",
      "          5       1.00      1.00      1.00       312\n",
      "          6       1.00      1.00      1.00       298\n",
      "          7       1.00      1.00      1.00       289\n",
      "          8       1.00      1.00      1.00       288\n",
      "          9       1.00      1.00      1.00       302\n",
      "\n",
      "avg / total       1.00      1.00      1.00      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>283</td>\n",
       "      <td>305</td>\n",
       "      <td>311</td>\n",
       "      <td>319</td>\n",
       "      <td>293</td>\n",
       "      <td>312</td>\n",
       "      <td>298</td>\n",
       "      <td>289</td>\n",
       "      <td>288</td>\n",
       "      <td>302</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          283    0    0    0    0    0    0    0    0    0   283\n",
       "1            0  305    0    0    0    0    0    0    0    0   305\n",
       "2            0    0  311    0    0    0    0    0    0    0   311\n",
       "3            0    0    0  319    0    0    0    0    0    0   319\n",
       "4            0    0    0    0  293    0    0    0    0    0   293\n",
       "5            0    0    0    0    0  312    0    0    0    0   312\n",
       "6            0    0    0    0    0    0  298    0    0    0   298\n",
       "7            0    0    0    0    0    0    0  289    0    0   289\n",
       "8            0    0    0    0    0    0    0    0  288    0   288\n",
       "9            0    0    0    0    0    0    0    0    0  302   302\n",
       "All        283  305  311  319  293  312  298  289  288  302  3000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_train, y_pred))\n",
    "\n",
    "# Print nicer homemade confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6491666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.59      0.60       119\n",
      "          1       0.79      0.86      0.82       125\n",
      "          2       0.45      0.46      0.46       112\n",
      "          3       0.57      0.53      0.55       124\n",
      "          4       0.57      0.57      0.57       124\n",
      "          5       0.74      0.66      0.69       114\n",
      "          6       0.37      0.39      0.38       119\n",
      "          7       0.78      0.82      0.80       118\n",
      "          8       0.84      0.80      0.82       133\n",
      "          9       0.76      0.78      0.77       112\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>6</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>115</td>\n",
       "      <td>137</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "      <td>124</td>\n",
       "      <td>102</td>\n",
       "      <td>124</td>\n",
       "      <td>124</td>\n",
       "      <td>127</td>\n",
       "      <td>115</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           70    6    5    9    3    3   22    0    1    0   119\n",
       "1            3  108    4    6    1    0    3    0    0    0   125\n",
       "2            2    4   52    9   21    0   21    0    0    3   112\n",
       "3           11   13    9   66    7    1   12    0    1    4   124\n",
       "4            3    4   19   10   71    0   16    0    1    0   124\n",
       "5            3    1    0    4    0   75    1   18    6    6   114\n",
       "6           19    0   23   11   14    0   46    0    4    2   119\n",
       "7            0    0    0    0    0   12    1   97    1    7   118\n",
       "8            2    1    3    0    3    6    2    3  107    6   133\n",
       "9            2    0    1    1    4    5    0    6    6   87   112\n",
       "All        115  137  116  116  124  102  124  124  127  115  1200"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_valid, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the tree on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6016666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.53      0.55       191\n",
      "          1       0.81      0.77      0.79       191\n",
      "          2       0.47      0.54      0.50       194\n",
      "          3       0.47      0.45      0.46       183\n",
      "          4       0.46      0.51      0.48       165\n",
      "          5       0.72      0.69      0.71       177\n",
      "          6       0.33      0.33      0.33       171\n",
      "          7       0.74      0.80      0.77       183\n",
      "          8       0.77      0.68      0.72       152\n",
      "          9       0.72      0.69      0.71       193\n",
      "\n",
      "avg / total       0.61      0.60      0.60      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>147</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>12</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>174</td>\n",
       "      <td>182</td>\n",
       "      <td>224</td>\n",
       "      <td>175</td>\n",
       "      <td>184</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>198</td>\n",
       "      <td>133</td>\n",
       "      <td>187</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          101    8   20   19    8    3   24    0    3    5   191\n",
       "1            8  147    7   15    6    2    6    0    0    0   191\n",
       "2            6    2  105   15   36    0   25    0    3    2   194\n",
       "3           25   17   13   82   14    2   21    0    5    4   183\n",
       "4            3    2   38   11   84    1   24    0    1    1   165\n",
       "5            1    0    2    6    0  123    1   28    2   14   177\n",
       "6           24    3   27   19   29    1   57    0    5    6   171\n",
       "7            0    0    1    0    0   22    0  147    4    9   183\n",
       "8            4    1    2    6    5    6    8    5  103   12   152\n",
       "9            2    2    9    2    2   11    6   18    7  134   193\n",
       "All        174  182  224  175  184  171  172  198  133  187  1800"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Simple Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "# print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print nicer confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Overiftted Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree, setting min samples per leaf to a sensible value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split = 200)\n",
    "my_tree = my_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6143333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.44      0.46       283\n",
      "          1       0.65      0.80      0.72       305\n",
      "          2       0.46      0.51      0.48       311\n",
      "          3       0.53      0.58      0.55       319\n",
      "          4       0.60      0.44      0.51       293\n",
      "          5       0.79      0.70      0.74       312\n",
      "          6       0.39      0.31      0.35       298\n",
      "          7       0.72      0.83      0.77       289\n",
      "          8       0.78      0.73      0.75       288\n",
      "          9       0.72      0.80      0.76       302\n",
      "\n",
      "avg / total       0.61      0.61      0.61      3000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>244</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>158</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>209</td>\n",
       "      <td>29</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>242</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>262</td>\n",
       "      <td>376</td>\n",
       "      <td>343</td>\n",
       "      <td>352</td>\n",
       "      <td>215</td>\n",
       "      <td>276</td>\n",
       "      <td>236</td>\n",
       "      <td>337</td>\n",
       "      <td>267</td>\n",
       "      <td>336</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          125   23   36   50    5    3   34    0    4    3   283\n",
       "1           27  244    9   14    1    0   10    0    0    0   305\n",
       "2           19   19  158   11   61    0   30    0    3   10   311\n",
       "3           56   31   15  185    3    0   11    0   16    2   319\n",
       "4            1   15   48   33  129    0   52    0    6    9   293\n",
       "5            1    2    1    5    0  217    0   58   11   17   312\n",
       "6           29   40   58   48   15    0   93    1    9    5   298\n",
       "7            0    0    0    0    0   25    0  241    4   19   289\n",
       "8            0    2   12    6    1    6    4   19  209   29   288\n",
       "9            4    0    6    0    0   25    2   18    5  242   302\n",
       "All        262  376  343  352  215  276  236  337  267  336  3000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the training data\n",
    "y_pred = my_tree.predict(X_train)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_train), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the performance of the decision tree on the **validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6008333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.43      0.47       119\n",
      "          1       0.67      0.83      0.74       125\n",
      "          2       0.39      0.45      0.41       112\n",
      "          3       0.49      0.58      0.53       124\n",
      "          4       0.56      0.35      0.43       124\n",
      "          5       0.78      0.71      0.74       114\n",
      "          6       0.31      0.28      0.29       119\n",
      "          7       0.75      0.81      0.78       118\n",
      "          8       0.85      0.77      0.81       133\n",
      "          9       0.66      0.79      0.72       112\n",
      "\n",
      "avg / total       0.60      0.60      0.59      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>98</td>\n",
       "      <td>155</td>\n",
       "      <td>129</td>\n",
       "      <td>148</td>\n",
       "      <td>77</td>\n",
       "      <td>104</td>\n",
       "      <td>107</td>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>133</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3   4    5    6    7    8    9   All\n",
       "True                                                           \n",
       "0          51   14   15   17   0    0   15    2    2    3   119\n",
       "1           9  104    4    5   0    0    3    0    0    0   125\n",
       "2           8    9   50    8  22    0   11    0    1    3   112\n",
       "3          15    8    7   72   2    0   10    0    4    6   124\n",
       "4           4    6   21   16  43    0   33    0    0    1   124\n",
       "5           0    1    0    5   0   81    0   19    3    5   114\n",
       "6           9   13   27   21  10    0   33    0    4    2   119\n",
       "7           0    0    0    0   0   14    0   96    1    7   118\n",
       "8           0    0    2    2   0    2    1    5  103   18   133\n",
       "9           2    0    3    2   0    7    1    6    3   88   112\n",
       "All        98  155  129  148  77  104  107  128  121  133  1200"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5811111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.41      0.45       191\n",
      "          1       0.67      0.80      0.73       191\n",
      "          2       0.45      0.54      0.49       194\n",
      "          3       0.43      0.47      0.45       183\n",
      "          4       0.58      0.46      0.51       165\n",
      "          5       0.74      0.66      0.70       177\n",
      "          6       0.37      0.32      0.34       171\n",
      "          7       0.71      0.75      0.73       183\n",
      "          8       0.75      0.65      0.70       152\n",
      "          9       0.61      0.74      0.67       193\n",
      "\n",
      "avg / total       0.58      0.58      0.58      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>25</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>142</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>152</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>201</td>\n",
       "      <td>131</td>\n",
       "      <td>158</td>\n",
       "      <td>145</td>\n",
       "      <td>194</td>\n",
       "      <td>132</td>\n",
       "      <td>231</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           78   20   21   33    4    0   25    1    4    5   191\n",
       "1            8  153   11   11    1    0    6    0    1    0   191\n",
       "2           11    7  104   15   33    0   14    0    3    7   194\n",
       "3           33   21   14   86    1    0   14    0    7    7   183\n",
       "4            3    7   36   13   76    0   24    0    1    5   165\n",
       "5            0    2    0    3    0  117    1   33    6   15   177\n",
       "6           14   15   30   31   14    1   54    0    4    8   171\n",
       "7            0    0    1    0    0   26    0  137    2   17   183\n",
       "8            0    2    5    6    2    3    3    7   99   25   152\n",
       "9            5    0    7    3    0   11    4   16    5  142   193\n",
       "All        152  227  229  201  131  158  145  194  132  231  1800"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Better Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True, dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Parameters Using a Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a cross validation to perfrom an evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64941176 0.62028302 0.58865248 0.61045131 0.6547619  0.64047619\n",
      " 0.62052506 0.63701923 0.63461538 0.62259615]\n"
     ]
    }
   ],
   "source": [
    "my_tree = tree.DecisionTreeClassifier(max_depth = 12)\n",
    "scores = cross_val_score(my_tree, X_train_plus_valid, y_train_plus_valid, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to using post pruning explicitly is to use a grid search through a large set of possible parameters. Here we try depths between 3 and 20 and different limits on the minimum number of samples per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=3, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=6, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=6, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n",
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=9, min_samples_split=200 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=9, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=12, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=12, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=15, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=18, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=18, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=21, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=21, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=24, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=24, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=27, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=30, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=30, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=33, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=33, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=36, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=36, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=39, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=39, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=42, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=42, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=45, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=45, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=48, min_samples_split=200 .............\n",
      "[CV]  criterion=gini, max_depth=48, min_samples_split=200, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=3, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=6, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=6, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=9, min_samples_split=200 ...........\n",
      "[CV]  criterion=entropy, max_depth=9, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=12, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=12, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=18, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=18, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=21, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=21, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=24, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=24, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=27, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=27, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=30, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=30, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=33, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=33, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=36, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=36, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=39, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=39, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=42, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=42, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=45, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=45, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=48, min_samples_split=200 ..........\n",
      "[CV]  criterion=entropy, max_depth=48, min_samples_split=200, total=   0.1s\n",
      "Best parameters set found on development set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02532506, 0.0382272 , 0.04199016, 0.03317487, 0.03084648,\n",
       "        0.03152657, 0.03250754, 0.03091455, 0.05038905, 0.0452745 ,\n",
       "        0.03412199, 0.03456795, 0.03083515, 0.03040802, 0.03279495,\n",
       "        0.03075755, 0.05155718, 0.07676804, 0.07985556, 0.07959497,\n",
       "        0.07532883, 0.07822955, 0.07764113, 0.07558751, 0.07790709,\n",
       "        0.08363056, 0.08617246, 0.07968545, 0.09648347, 0.09617496,\n",
       "        0.11171961, 0.11171222]),\n",
       " 'mean_score_time': array([0.00101399, 0.00089347, 0.0017004 , 0.00081933, 0.0007602 ,\n",
       "        0.00084996, 0.0007782 , 0.00079548, 0.00165844, 0.00108397,\n",
       "        0.00082052, 0.00088   , 0.00077736, 0.00075758, 0.00085151,\n",
       "        0.00077951, 0.00079536, 0.00077856, 0.00090587, 0.00083208,\n",
       "        0.00080872, 0.00081956, 0.00085294, 0.00077546, 0.00079858,\n",
       "        0.00078797, 0.00100505, 0.00078106, 0.001001  , 0.00087297,\n",
       "        0.00170791, 0.00134134]),\n",
       " 'mean_test_score': array([0.51642857, 0.57142857, 0.57142857, 0.57142857, 0.57142857,\n",
       "        0.57142857, 0.57142857, 0.57142857, 0.57142857, 0.57142857,\n",
       "        0.57142857, 0.57142857, 0.57142857, 0.57142857, 0.57142857,\n",
       "        0.57142857, 0.51142857, 0.5547619 , 0.55214286, 0.55214286,\n",
       "        0.55214286, 0.55214286, 0.55214286, 0.55214286, 0.55214286,\n",
       "        0.55214286, 0.55214286, 0.55214286, 0.55214286, 0.55214286,\n",
       "        0.55214286, 0.55214286]),\n",
       " 'mean_train_score': array([0.52929666, 0.61359683, 0.61359683, 0.61359683, 0.61359683,\n",
       "        0.61359683, 0.61359683, 0.61359683, 0.61359683, 0.61359683,\n",
       "        0.61359683, 0.61359683, 0.61359683, 0.61359683, 0.61359683,\n",
       "        0.61359683, 0.52596808, 0.59502809, 0.60097197, 0.60097197,\n",
       "        0.60097197, 0.60097197, 0.60097197, 0.60097197, 0.60097197,\n",
       "        0.60097197, 0.60097197, 0.60097197, 0.60097197, 0.60097197,\n",
       "        0.60097197, 0.60097197]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42,\n",
       "                    45, 48, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36,\n",
       "                    39, 42, 45, 48],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200,\n",
       "                    200, 200, 200, 200, 200, 200, 200, 200, 200, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'gini', 'max_depth': 48, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 33, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 36, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 39, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 42, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 45, 'min_samples_split': 200},\n",
       "  {'criterion': 'entropy', 'max_depth': 48, 'min_samples_split': 200}],\n",
       " 'rank_test_score': array([31,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 32,\n",
       "        16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "       dtype=int32),\n",
       " 'split0_test_score': array([0.51592962, 0.56966239, 0.56966239, 0.56966239, 0.56966239,\n",
       "        0.56966239, 0.56966239, 0.56966239, 0.56966239, 0.56966239,\n",
       "        0.56966239, 0.56966239, 0.56966239, 0.56966239, 0.56966239,\n",
       "        0.56966239, 0.51640514, 0.55206847, 0.55206847, 0.55206847,\n",
       "        0.55206847, 0.55206847, 0.55206847, 0.55206847, 0.55206847,\n",
       "        0.55206847, 0.55206847, 0.55206847, 0.55206847, 0.55206847,\n",
       "        0.55206847, 0.55206847]),\n",
       " 'split0_train_score': array([0.53695756, 0.63137816, 0.63137816, 0.63137816, 0.63137816,\n",
       "        0.63137816, 0.63137816, 0.63137816, 0.63137816, 0.63137816,\n",
       "        0.63137816, 0.63137816, 0.63137816, 0.63137816, 0.63137816,\n",
       "        0.63137816, 0.53695756, 0.61468765, 0.61468765, 0.61468765,\n",
       "        0.61468765, 0.61468765, 0.61468765, 0.61468765, 0.61468765,\n",
       "        0.61468765, 0.61468765, 0.61468765, 0.61468765, 0.61468765,\n",
       "        0.61468765, 0.61468765]),\n",
       " 'split1_test_score': array([0.51692895, 0.57319981, 0.57319981, 0.57319981, 0.57319981,\n",
       "        0.57319981, 0.57319981, 0.57319981, 0.57319981, 0.57319981,\n",
       "        0.57319981, 0.57319981, 0.57319981, 0.57319981, 0.57319981,\n",
       "        0.57319981, 0.50643777, 0.55746304, 0.55221745, 0.55221745,\n",
       "        0.55221745, 0.55221745, 0.55221745, 0.55221745, 0.55221745,\n",
       "        0.55221745, 0.55221745, 0.55221745, 0.55221745, 0.55221745,\n",
       "        0.55221745, 0.55221745]),\n",
       " 'split1_train_score': array([0.52163576, 0.5958155 , 0.5958155 , 0.5958155 , 0.5958155 ,\n",
       "        0.5958155 , 0.5958155 , 0.5958155 , 0.5958155 , 0.5958155 ,\n",
       "        0.5958155 , 0.5958155 , 0.5958155 , 0.5958155 , 0.5958155 ,\n",
       "        0.5958155 , 0.5149786 , 0.57536852, 0.5872563 , 0.5872563 ,\n",
       "        0.5872563 , 0.5872563 , 0.5872563 , 0.5872563 , 0.5872563 ,\n",
       "        0.5872563 , 0.5872563 , 0.5872563 , 0.5872563 , 0.5872563 ,\n",
       "        0.5872563 , 0.5872563 ]),\n",
       " 'std_fit_time': array([6.41345978e-05, 2.89118290e-03, 8.15987587e-04, 2.79605389e-03,\n",
       "        5.66601753e-04, 4.86612320e-04, 2.65252590e-03, 3.64780426e-05,\n",
       "        1.16610527e-03, 9.33551788e-03, 3.33786011e-03, 2.68113613e-03,\n",
       "        4.42981720e-04, 5.97834587e-04, 1.23286247e-03, 8.68439674e-04,\n",
       "        8.46028328e-04, 3.66008282e-03, 1.61039829e-03, 1.43587589e-03,\n",
       "        4.28915024e-04, 2.57050991e-03, 1.36315823e-03, 7.64608383e-04,\n",
       "        2.03609467e-03, 6.71553612e-03, 1.85859203e-03, 5.07259369e-03,\n",
       "        1.39305592e-02, 2.08091736e-03, 1.61323547e-02, 1.94661617e-02]),\n",
       " 'std_score_time': array([1.30176544e-04, 1.15275383e-04, 4.11510468e-04, 5.94854355e-05,\n",
       "        5.12599945e-06, 2.00271606e-05, 1.64508820e-05, 6.13927841e-05,\n",
       "        5.28573990e-04, 1.31964684e-04, 4.85181808e-05, 1.59740448e-05,\n",
       "        1.63316727e-05, 1.94311142e-05, 4.85181808e-05, 1.41859055e-05,\n",
       "        6.65187836e-05, 1.25169754e-05, 1.05977058e-04, 7.86781311e-06,\n",
       "        2.55107880e-05, 3.54051590e-05, 7.98702240e-06, 4.41074371e-06,\n",
       "        2.15768814e-05, 3.09944153e-06, 5.09023666e-05, 2.19345093e-05,\n",
       "        1.41739845e-04, 7.98702240e-06, 6.88195229e-04, 4.68492508e-04]),\n",
       " 'std_test_score': array([4.99660374e-04, 1.76870929e-03, 1.76870929e-03, 1.76870929e-03,\n",
       "        1.76870929e-03, 1.76870929e-03, 1.76870929e-03, 1.76870929e-03,\n",
       "        1.76870929e-03, 1.76870929e-03, 1.76870929e-03, 1.76870929e-03,\n",
       "        1.76870929e-03, 1.76870929e-03, 1.76870929e-03, 1.76870929e-03,\n",
       "        4.98367855e-03, 2.69728166e-03, 7.44898719e-05, 7.44898719e-05,\n",
       "        7.44898719e-05, 7.44898719e-05, 7.44898719e-05, 7.44898719e-05,\n",
       "        7.44898719e-05, 7.44898719e-05, 7.44898719e-05, 7.44898719e-05,\n",
       "        7.44898719e-05, 7.44898719e-05, 7.44898719e-05, 7.44898719e-05]),\n",
       " 'std_train_score': array([0.0076609 , 0.01778133, 0.01778133, 0.01778133, 0.01778133,\n",
       "        0.01778133, 0.01778133, 0.01778133, 0.01778133, 0.01778133,\n",
       "        0.01778133, 0.01778133, 0.01778133, 0.01778133, 0.01778133,\n",
       "        0.01778133, 0.01098948, 0.01965956, 0.01371567, 0.01371567,\n",
       "        0.01371567, 0.01371567, 0.01371567, 0.01371567, 0.01371567,\n",
       "        0.01371567, 0.01371567, 0.01371567, 0.01371567, 0.01371567,\n",
       "        0.01371567, 0.01371567])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
    "             'max_depth': list(range(3, 50, 3)), \\\n",
    "             'min_samples_split': [200]}\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
    "                                param_grid, cv=cv_folds, verbose = 2, \\\n",
    "                            return_train_score=True)\n",
    "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "display(my_tuned_tree.best_params_)\n",
    "model_tuned_params_list[\"Tuned Tree\"] = my_tuned_tree.best_params_\n",
    "display(my_tuned_tree.best_score_)\n",
    "display(my_tuned_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the tuned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5794444444444444\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.32      0.44       191\n",
      "          1       0.62      0.81      0.70       191\n",
      "          2       0.53      0.40      0.45       194\n",
      "          3       0.34      0.66      0.45       183\n",
      "          4       0.59      0.55      0.57       165\n",
      "          5       0.74      0.69      0.72       177\n",
      "          6       0.32      0.22      0.26       171\n",
      "          7       0.73      0.74      0.73       183\n",
      "          8       0.80      0.70      0.75       152\n",
      "          9       0.67      0.72      0.69       193\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>138</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>90</td>\n",
       "      <td>252</td>\n",
       "      <td>145</td>\n",
       "      <td>354</td>\n",
       "      <td>153</td>\n",
       "      <td>166</td>\n",
       "      <td>116</td>\n",
       "      <td>185</td>\n",
       "      <td>132</td>\n",
       "      <td>207</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                            \n",
       "0          62   30    9   64    6    0   14    0    3    3   191\n",
       "1           0  155    5   30    1    0    0    0    0    0   191\n",
       "2           2   12   77   37   26    0   36    0    1    3   194\n",
       "3          13   29    7  120    4    0    5    0    3    2   183\n",
       "4           0    7   31   20   90    0   14    0    2    1   165\n",
       "5           0    1    0    6    0  123    0   29    5   13   177\n",
       "6          11   17   15   60   16    2   37    0    4    9   171\n",
       "7           0    0    0    0    0   27    0  135    1   20   183\n",
       "8           2    1    1    6    5    2    3    8  106   18   152\n",
       "9           0    0    0   11    5   12    7   13    7  138   193\n",
       "All        90  252  145  354  153  166  116  185  132  207  1800"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_tree.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Tree\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_tree = tree.DecisionTreeClassifier(min_samples_split=200, criterion='gini', max_depth=8)\n",
    "best_tree = best_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily use the same patterns to train other types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=200,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.RandomForestClassifier(n_estimators=300, \\\n",
    "                                           max_features = 3,\\\n",
    "                                           min_samples_split=200)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.43      0.51       119\n",
      "          1       0.62      0.82      0.71       125\n",
      "          2       0.49      0.46      0.47       112\n",
      "          3       0.39      0.73      0.50       124\n",
      "          4       0.52      0.61      0.57       124\n",
      "          5       0.74      0.75      0.74       114\n",
      "          6       0.00      0.00      0.00       119\n",
      "          7       0.80      0.78      0.79       118\n",
      "          8       0.91      0.86      0.88       133\n",
      "          9       0.83      0.81      0.82       112\n",
      "\n",
      "avg / total       0.59      0.63      0.60      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>115</td>\n",
       "      <td>6</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>80</td>\n",
       "      <td>166</td>\n",
       "      <td>107</td>\n",
       "      <td>233</td>\n",
       "      <td>145</td>\n",
       "      <td>117</td>\n",
       "      <td>115</td>\n",
       "      <td>127</td>\n",
       "      <td>110</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4    5    7    8    9   All\n",
       "True                                                       \n",
       "0          51   31    6   25    2    2    0    2    0   119\n",
       "1           4  103    0   18    0    0    0    0    0   125\n",
       "2           2    7   52   26   24    0    0    1    0   112\n",
       "3           9   12    6   90    4    1    0    2    0   124\n",
       "4           0    5   17   26   76    0    0    0    0   124\n",
       "5           0    0    0    7    0   86   16    1    4   114\n",
       "6          14    8   22   37   33    0    0    4    1   119\n",
       "7           0    0    0    0    0   18   92    0    8   118\n",
       "8           0    0    2    0    2    3    5  115    6   133\n",
       "9           0    0    2    4    4    7    2    2   91   112\n",
       "All        80  166  107  233  145  117  115  127  110  1200"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=100 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=2, min_samples_split=200, n_estimators=100, total=   0.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=150, total=   0.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=200, total=   0.7s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.9s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=250, total=   0.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   1.0s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=300, total=   1.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.2s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=350, total=   1.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.4s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=400, total=   1.3s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.6s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=450, total=   1.5s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=2, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=2, min_samples_split=200, n_estimators=500, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=150, total=   0.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=200, total=   0.9s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.1s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=300, total=   1.2s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=350, total=   1.4s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.5s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=400, total=   1.6s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=450, total=   1.8s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   2.0s\n",
      "[CV] max_features=4, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=4, min_samples_split=200, n_estimators=500, total=   1.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=100, total=   0.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=150, total=   0.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=200, total=   1.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=250, total=   1.2s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=300, total=   1.5s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=350, total=   1.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   2.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=400, total=   2.0s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=450, total=   2.7s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.9s\n",
      "[CV] max_features=6, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=6, min_samples_split=200, n_estimators=500, total=   2.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=100 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=100, total=   0.7s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   1.1s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=150 .........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=8, min_samples_split=200, n_estimators=150, total=   1.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=200 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=200, total=   1.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.5s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=250 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=250, total=   1.8s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   2.2s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=300 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=300, total=   2.3s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=350 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=350, total=   2.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.4s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=400 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=400, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   3.0s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=450 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=450, total=   2.6s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.9s\n",
      "[CV] max_features=8, min_samples_split=200, n_estimators=500 .........\n",
      "[CV]  max_features=8, min_samples_split=200, n_estimators=500, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'max_features': 8, 'min_samples_split': 200, 'n_estimators': 450}\n",
      "0.6114285714285714\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(100, 501, 50)), 'max_features': list(range(2, 10, 2)), 'min_samples_split': [200] }\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Random Forest\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.60      0.63       191\n",
      "          1       0.78      0.83      0.81       191\n",
      "          2       0.53      0.59      0.56       194\n",
      "          3       0.46      0.63      0.53       183\n",
      "          4       0.53      0.66      0.59       165\n",
      "          5       0.71      0.73      0.72       177\n",
      "          6       0.36      0.13      0.20       171\n",
      "          7       0.79      0.74      0.77       183\n",
      "          8       0.83      0.78      0.81       152\n",
      "          9       0.76      0.72      0.74       193\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>11</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>175</td>\n",
       "      <td>203</td>\n",
       "      <td>218</td>\n",
       "      <td>254</td>\n",
       "      <td>204</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>172</td>\n",
       "      <td>143</td>\n",
       "      <td>184</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0          115   15   10   30    8    0   7    0    5    1   191\n",
       "1            6  159    0   18    1    0   7    0    0    0   191\n",
       "2            3    7  115   21   34    0  11    0    2    1   194\n",
       "3           19   20   10  116    8    1   5    0    3    1   183\n",
       "4            1    0   32   12  109    0  10    0    0    1   165\n",
       "5            0    0    0    7    0  130   1   23    3   13   177\n",
       "6           29    2   37   36   35    2  23    0    4    3   171\n",
       "7            0    0    0    0    0   31   0  136    2   14   183\n",
       "8            2    0    3    3    5    4   0    5  119   11   152\n",
       "9            0    0   11   11    4   15   0    8    5  139   193\n",
       "All        175  203  218  254  204  183  64  172  143  184  1800"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Random Forest\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=50, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=1.0, n_estimators=10, n_jobs=1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.BaggingClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 50), \\\n",
    "                                      n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.63      0.61       119\n",
      "          1       0.78      0.85      0.81       125\n",
      "          2       0.50      0.47      0.48       112\n",
      "          3       0.48      0.59      0.53       124\n",
      "          4       0.53      0.62      0.57       124\n",
      "          5       0.73      0.73      0.73       114\n",
      "          6       0.37      0.18      0.24       119\n",
      "          7       0.75      0.81      0.78       118\n",
      "          8       0.90      0.77      0.83       133\n",
      "          9       0.69      0.75      0.72       112\n",
      "\n",
      "avg / total       0.64      0.64      0.63      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>15</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>125</td>\n",
       "      <td>136</td>\n",
       "      <td>107</td>\n",
       "      <td>153</td>\n",
       "      <td>146</td>\n",
       "      <td>113</td>\n",
       "      <td>57</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>121</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           75    9    7   12    1    0  10    2    1    2   119\n",
       "1            5  106    1   13    0    0   0    0    0    0   125\n",
       "2            6    4   53    9   28    0  10    0    1    1   112\n",
       "3           14   11    7   73    5    4   6    0    0    4   124\n",
       "4            2    3   11   22   77    0   7    0    1    1   124\n",
       "5            0    0    0    5    0   83   2   19    0    5   114\n",
       "6           21    3   22   15   30    1  21    0    4    2   119\n",
       "7            0    0    0    0    0   14   0   96    1    7   118\n",
       "8            0    0    2    1    2    4   1    5  103   15   133\n",
       "9            2    0    4    3    3    7   0    6    3   84   112\n",
       "All        125  136  107  153  146  113  57  128  114  121  1200"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   1.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   0.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=   2.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=   2.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=   3.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=   3.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=   4.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=   4.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=   5.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=   5.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=   6.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=   6.0s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350, total=   7.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350, total=   6.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400, total=   7.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400, total=   7.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450, total=   8.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450, total=   8.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500, total=   9.5s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500, total=   9.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 400}\n",
      "0.4116666666666667\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    "  'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned Bagging\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5727777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.51      0.53       191\n",
      "          1       0.61      0.83      0.70       191\n",
      "          2       0.49      0.41      0.45       194\n",
      "          3       0.41      0.50      0.45       183\n",
      "          4       0.52      0.58      0.55       165\n",
      "          5       0.70      0.70      0.70       177\n",
      "          6       0.20      0.12      0.15       171\n",
      "          7       0.73      0.74      0.73       183\n",
      "          8       0.68      0.70      0.69       152\n",
      "          9       0.69      0.65      0.67       193\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>125</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>175</td>\n",
       "      <td>260</td>\n",
       "      <td>162</td>\n",
       "      <td>221</td>\n",
       "      <td>183</td>\n",
       "      <td>177</td>\n",
       "      <td>99</td>\n",
       "      <td>186</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           97   23   14   23    6    0  18    1    4    5   191\n",
       "1            4  158    0   18    1    0  10    0    0    0   191\n",
       "2            9   29   80   20   34    0  19    0    1    2   194\n",
       "3           24   32    2   91    4    6  15    0    3    6   183\n",
       "4            9    8   24    9   95    0  16    0    3    1   165\n",
       "5            0    0    0    7    1  124   1   30    0   14   177\n",
       "6           30    7   34   37   28    2  20    0    7    6   171\n",
       "7            0    0    0    0    0   27   0  135   10   11   183\n",
       "8            0    2    2    9    8    6   0    7  106   12   152\n",
       "9            2    1    6    7    6   12   0   13   21  125   193\n",
       "All        175  260  162  221  183  177  99  186  155  182  1800"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Bagging\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=200, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.0, n_estimators=10, random_state=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = ensemble.AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf = 200), \\\n",
    "                                       n_estimators=10)\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42916666666666664\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.28      0.27       119\n",
      "          1       0.91      0.38      0.54       125\n",
      "          2       0.35      0.36      0.35       112\n",
      "          3       0.42      0.52      0.47       124\n",
      "          4       0.24      0.17      0.20       124\n",
      "          5       0.51      0.65      0.57       114\n",
      "          6       0.22      0.39      0.28       119\n",
      "          7       0.46      0.31      0.37       118\n",
      "          8       0.63      0.81      0.71       133\n",
      "          9       0.70      0.40      0.51       112\n",
      "\n",
      "avg / total       0.47      0.43      0.43      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>122</td>\n",
       "      <td>53</td>\n",
       "      <td>115</td>\n",
       "      <td>151</td>\n",
       "      <td>89</td>\n",
       "      <td>146</td>\n",
       "      <td>211</td>\n",
       "      <td>78</td>\n",
       "      <td>171</td>\n",
       "      <td>64</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0   1    2    3   4    5    6   7    8   9   All\n",
       "True                                                         \n",
       "0           33   2    7   31  14    0   29   0    2   1   119\n",
       "1           46  48    5   17   7    0    2   0    0   0   125\n",
       "2            9   0   40    6  19    0   37   0    1   0   112\n",
       "3           12   3   10   64   8    1   25   0    1   0   124\n",
       "4            8   0   24   14  21    0   56   0    1   0   124\n",
       "5            2   0    0    4   0   74    1  22    4   7   114\n",
       "6           10   0   24   15  18    1   46   0    4   1   119\n",
       "7            0   0    0    0   0   62    0  36   17   3   118\n",
       "8            1   0    0    0   2    2   11   2  108   7   133\n",
       "9            1   0    5    0   0    6    4  18   33  45   112\n",
       "All        122  53  115  151  89  146  211  78  171  64  1200"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the validation data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   2.3s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=50, total=   2.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=   4.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=100, total=   4.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=   6.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=150, total=   6.2s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=   9.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=200, total=   8.9s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=  10.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=250, total=  10.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=  12.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=300, total=  12.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350, total=  14.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=350, total=  15.1s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400, total=  18.4s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=400, total=  16.7s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450, total=  17.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=450, total=  18.8s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500, total=  20.6s\n",
      "[CV] base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500 \n",
      "[CV]  base_estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), n_estimators=500, total=  19.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=200, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), 'n_estimators': 400}\n",
      "0.5914285714285714\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'n_estimators': list(range(50, 501, 50)),\n",
    " 'base_estimator': [tree.DecisionTreeClassifier(criterion=\"entropy\", max_depth = 6, min_samples_leaf = 200)]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned AdaBoost\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6188888888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65       191\n",
      "          1       0.91      0.80      0.85       191\n",
      "          2       0.57      0.61      0.59       194\n",
      "          3       0.51      0.53      0.52       183\n",
      "          4       0.50      0.61      0.55       165\n",
      "          5       0.72      0.45      0.55       177\n",
      "          6       0.33      0.35      0.34       171\n",
      "          7       0.59      0.82      0.69       183\n",
      "          8       0.69      0.77      0.73       152\n",
      "          9       0.82      0.62      0.71       193\n",
      "\n",
      "avg / total       0.64      0.62      0.62      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>9</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>179</td>\n",
       "      <td>169</td>\n",
       "      <td>207</td>\n",
       "      <td>191</td>\n",
       "      <td>199</td>\n",
       "      <td>109</td>\n",
       "      <td>178</td>\n",
       "      <td>253</td>\n",
       "      <td>169</td>\n",
       "      <td>146</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          120    5    6   26    9    0   23    0    2    0   191\n",
       "1            5  153    2   20    7    0    4    0    0    0   191\n",
       "2            5    1  119    9   31    0   27    0    1    1   194\n",
       "3           19   10    9   97   17    5   25    0    0    1   183\n",
       "4            2    0   26    7  100    0   29    0    1    0   165\n",
       "5            1    0    2    6    0   79    1   71    7   10   177\n",
       "6           26    0   31   16   32    0   59    0    5    2   171\n",
       "7            0    0    0    0    0   15    1  150   14    3   183\n",
       "8            0    0    5    5    3    4    6    3  117    9   152\n",
       "9            1    0    7    5    0    6    3   29   22  120   193\n",
       "All        179  169  207  191  199  109  178  253  169  146  1800"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned AdaBoost\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same job with logistic regression\n",
    "my_model = linear_model.LogisticRegression()\n",
    "my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.66      0.67       119\n",
      "          1       0.75      0.90      0.82       125\n",
      "          2       0.50      0.52      0.51       112\n",
      "          3       0.54      0.68      0.60       124\n",
      "          4       0.55      0.50      0.52       124\n",
      "          5       0.67      0.72      0.69       114\n",
      "          6       0.46      0.26      0.33       119\n",
      "          7       0.82      0.82      0.82       118\n",
      "          8       0.84      0.74      0.79       133\n",
      "          9       0.75      0.81      0.78       112\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>114</td>\n",
       "      <td>150</td>\n",
       "      <td>117</td>\n",
       "      <td>157</td>\n",
       "      <td>113</td>\n",
       "      <td>122</td>\n",
       "      <td>68</td>\n",
       "      <td>119</td>\n",
       "      <td>118</td>\n",
       "      <td>122</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           78   16    3   15    0    2   5    0    0    0   119\n",
       "1            1  113    1    9    0    1   0    0    0    0   125\n",
       "2            3    5   58   12   16    5   9    0    2    2   112\n",
       "3           15    5   11   84    1    3   5    0    0    0   124\n",
       "4            2    8   17   13   62    1  12    0    9    0   124\n",
       "5            0    0    0    8    0   82   0   15    1    8   114\n",
       "6           15    3   18   12   28    7  31    0    4    1   119\n",
       "7            0    0    0    0    0   15   0   97    1    5   118\n",
       "8            0    0    2    3    6    2   1    5   99   15   133\n",
       "9            0    0    7    1    0    4   5    2    2   91   112\n",
       "All        114  150  117  157  113  122  68  119  118  122  1200"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=0.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.2, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.4, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.6, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=1.8, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n",
      "[CV] C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear .........\n",
      "[CV]  C=2.0, max_iter=1000, multi_class=ovr, solver=liblinear, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 1.8, 'max_iter': 1000, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
      "0.6309523809523809\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    " {'multi_class': ['ovr'], \n",
    " 'C': [x / 10.0 for x in range(2, 21, 2)],\n",
    " 'solver':['liblinear'],\n",
    "  'max_iter':[1000]}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(linear_model.LogisticRegression(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Logistic Regression\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6277777777777778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.58      0.63       191\n",
      "          1       0.69      0.88      0.78       191\n",
      "          2       0.49      0.55      0.52       194\n",
      "          3       0.49      0.54      0.51       183\n",
      "          4       0.51      0.53      0.52       165\n",
      "          5       0.67      0.69      0.68       177\n",
      "          6       0.40      0.27      0.33       171\n",
      "          7       0.78      0.79      0.78       183\n",
      "          8       0.76      0.70      0.73       152\n",
      "          9       0.76      0.73      0.74       193\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>10</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>140</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>158</td>\n",
       "      <td>244</td>\n",
       "      <td>215</td>\n",
       "      <td>202</td>\n",
       "      <td>170</td>\n",
       "      <td>183</td>\n",
       "      <td>117</td>\n",
       "      <td>185</td>\n",
       "      <td>141</td>\n",
       "      <td>185</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          110   23   13   24    4    2    6    1    8    0   191\n",
       "1            3  169    2   16    0    0    1    0    0    0   191\n",
       "2            3    9  106   19   33    0   20    0    3    1   194\n",
       "3           14   32   11   98    6    7   13    0    1    1   183\n",
       "4            2    4   34   11   87    2   16    0    8    1   165\n",
       "5            1    0    1    6    0  122    2   25    1   19   177\n",
       "6           24    6   26   24   33    6   47    0    3    2   171\n",
       "7            0    0    0    0    1   27    0  144    0   11   183\n",
       "8            0    1    2    3    6    9    6    8  107   10   152\n",
       "9            1    0   20    1    0    8    6    7   10  140   193\n",
       "All        158  244  215  202  170  183  117  185  141  185  1800"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned Logistic Regression\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7233333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.61      0.65       119\n",
      "          1       0.77      0.96      0.85       125\n",
      "          2       0.53      0.61      0.57       112\n",
      "          3       0.61      0.73      0.67       124\n",
      "          4       0.63      0.57      0.60       124\n",
      "          5       0.82      0.74      0.78       114\n",
      "          6       0.50      0.42      0.45       119\n",
      "          7       0.86      0.89      0.88       118\n",
      "          8       0.96      0.81      0.88       133\n",
      "          9       0.84      0.88      0.86       112\n",
      "\n",
      "avg / total       0.73      0.72      0.72      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>101</td>\n",
       "      <td>156</td>\n",
       "      <td>128</td>\n",
       "      <td>148</td>\n",
       "      <td>112</td>\n",
       "      <td>102</td>\n",
       "      <td>101</td>\n",
       "      <td>122</td>\n",
       "      <td>112</td>\n",
       "      <td>118</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0           72   15    7   11    1    1   10    0    2    0   119\n",
       "1            1  120    0    3    0    0    1    0    0    0   125\n",
       "2            1    3   68    5   19    0   15    0    0    1   112\n",
       "3            4   13    8   91    2    0    6    0    0    0   124\n",
       "4            3    5   16   12   71    0   16    0    0    1   124\n",
       "5            1    0    0   10    0   84    1   10    1    7   114\n",
       "6           18    0   24   10   15    0   50    0    1    1   119\n",
       "7            0    0    0    0    0   11    0  105    0    2   118\n",
       "8            0    0    3    3    4    2    0    6  108    7   133\n",
       "9            1    0    2    3    0    4    2    1    0   99   112\n",
       "All        101  156  128  148  112  102  101  122  112  118  1200"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................................... n_neighbors=1, total=   0.1s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................................... n_neighbors=1, total=   0.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.1s\n",
      "[CV] n_neighbors=6 ...................................................\n",
      "[CV] .................................... n_neighbors=6, total=   0.1s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.2s\n",
      "[CV] n_neighbors=11 ..................................................\n",
      "[CV] ................................... n_neighbors=11, total=   0.1s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.2s\n",
      "[CV] n_neighbors=16 ..................................................\n",
      "[CV] ................................... n_neighbors=16, total=   0.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.2s\n",
      "[CV] n_neighbors=21 ..................................................\n",
      "[CV] ................................... n_neighbors=21, total=   0.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.2s\n",
      "[CV] n_neighbors=26 ..................................................\n",
      "[CV] ................................... n_neighbors=26, total=   0.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.2s\n",
      "[CV] n_neighbors=31 ..................................................\n",
      "[CV] ................................... n_neighbors=31, total=   0.2s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.2s\n",
      "[CV] n_neighbors=36 ..................................................\n",
      "[CV] ................................... n_neighbors=36, total=   0.2s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.3s\n",
      "[CV] n_neighbors=41 ..................................................\n",
      "[CV] ................................... n_neighbors=41, total=   0.2s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.3s\n",
      "[CV] n_neighbors=46 ..................................................\n",
      "[CV] ................................... n_neighbors=46, total=   0.2s\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 6}\n",
      "0.6852380952380952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    7.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'n_neighbors': list(range(1, 50, 5))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neighbors.KNeighborsClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned kNN\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6933333333333334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.69      0.69       191\n",
      "          1       0.76      0.93      0.83       191\n",
      "          2       0.56      0.63      0.59       194\n",
      "          3       0.59      0.58      0.59       183\n",
      "          4       0.56      0.62      0.59       165\n",
      "          5       0.76      0.71      0.73       177\n",
      "          6       0.46      0.35      0.39       171\n",
      "          7       0.85      0.79      0.82       183\n",
      "          8       0.96      0.79      0.87       152\n",
      "          9       0.76      0.82      0.79       193\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>122</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>186</td>\n",
       "      <td>233</td>\n",
       "      <td>217</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>166</td>\n",
       "      <td>129</td>\n",
       "      <td>171</td>\n",
       "      <td>125</td>\n",
       "      <td>208</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          131   16    6   17    6    0   13    0    2    0   191\n",
       "1            3  177    1    7    0    0    3    0    0    0   191\n",
       "2            5    5  122    5   31    0   21    0    0    5   194\n",
       "3           13   30   11  107    8    0   13    0    0    1   183\n",
       "4            2    1   33   12  103    0   13    0    0    1   165\n",
       "5            1    0    1    7    0  126    2   18    1   21   177\n",
       "6           29    4   36   14   25    0   59    0    0    4   171\n",
       "7            0    0    0    0    1   26    0  145    0   11   183\n",
       "8            1    0    3    5    5    2    3    6  120    7   152\n",
       "9            1    0    4    8    4   12    2    2    2  158   193\n",
       "All        186  233  217  182  183  166  129  171  125  208  1800"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned kNN\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate a simple model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same job with random forests\n",
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(300, 100))\n",
    "my_model = my_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7275\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.70      0.72       119\n",
      "          1       0.96      0.87      0.91       125\n",
      "          2       0.50      0.62      0.56       112\n",
      "          3       0.58      0.80      0.67       124\n",
      "          4       0.71      0.57      0.63       124\n",
      "          5       0.71      0.85      0.78       114\n",
      "          6       0.45      0.34      0.39       119\n",
      "          7       0.92      0.78      0.84       118\n",
      "          8       0.92      0.88      0.90       133\n",
      "          9       0.85      0.84      0.85       112\n",
      "\n",
      "avg / total       0.74      0.73      0.73      1200\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>111</td>\n",
       "      <td>114</td>\n",
       "      <td>139</td>\n",
       "      <td>172</td>\n",
       "      <td>100</td>\n",
       "      <td>136</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>127</td>\n",
       "      <td>110</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5   6    7    8    9   All\n",
       "True                                                            \n",
       "0           83    2    7   13    0    1  11    0    2    0   119\n",
       "1            0  109    1   13    0    0   2    0    0    0   125\n",
       "2            2    0   70    6   11    0  19    0    1    3   112\n",
       "3            9    2    8   99    0    2   4    0    0    0   124\n",
       "4            2    1   19   18   71    0  13    0    0    0   124\n",
       "5            0    0    0    6    0   97   0    6    2    3   114\n",
       "6           15    0   26   15   17    2  41    0    2    1   119\n",
       "7            0    0    0    0    0   22   0   92    0    4   118\n",
       "8            0    0    3    1    1    4   0    2  117    5   133\n",
       "9            0    0    5    1    0    8   1    0    3   94   112\n",
       "All        111  114  139  172  100  136  91  100  127  110  1200"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(X_valid)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_valid, y_pred) # , normalize=True, sample_weight=None\n",
    "model_valid_accuracy_comparisons[\"MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_valid, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_valid), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose parameters using a grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n",
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   3.0s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=400 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ alpha=0.1, hidden_layer_sizes=400, total=   2.9s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   5.6s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200) ........................\n",
      "[CV] ......... alpha=0.1, hidden_layer_sizes=(400, 200), total=   3.8s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=   4.4s\n",
      "[CV] alpha=0.1, hidden_layer_sizes=(400, 200, 100) ...................\n",
      "[CV] .... alpha=0.1, hidden_layer_sizes=(400, 200, 100), total=   5.4s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   4.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=400 ..............................\n",
      "[CV] ............... alpha=0.01, hidden_layer_sizes=400, total=   3.1s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   7.3s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200) .......................\n",
      "[CV] ........ alpha=0.01, hidden_layer_sizes=(400, 200), total=   5.8s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=   4.6s\n",
      "[CV] alpha=0.01, hidden_layer_sizes=(400, 200, 100) ..................\n",
      "[CV] ... alpha=0.01, hidden_layer_sizes=(400, 200, 100), total=   6.5s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   4.3s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=0.001, hidden_layer_sizes=400, total=   3.5s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=   4.7s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=0.001, hidden_layer_sizes=(400, 200), total=   5.4s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=   4.9s\n",
      "[CV] alpha=0.001, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=0.001, hidden_layer_sizes=(400, 200, 100), total=   4.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   3.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=400 ............................\n",
      "[CV] ............. alpha=0.0001, hidden_layer_sizes=400, total=   3.2s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=   6.9s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200) .....................\n",
      "[CV] ...... alpha=0.0001, hidden_layer_sizes=(400, 200), total=   5.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=   2.7s\n",
      "[CV] alpha=0.0001, hidden_layer_sizes=(400, 200, 100) ................\n",
      "[CV] . alpha=0.0001, hidden_layer_sizes=(400, 200, 100), total=   3.4s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   3.1s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-05, hidden_layer_sizes=400, total=   4.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=   4.3s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-05, hidden_layer_sizes=(400, 200), total=   3.0s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=   3.8s\n",
      "[CV] alpha=1e-05, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-05, hidden_layer_sizes=(400, 200, 100), total=   6.9s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   2.6s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=400 .............................\n",
      "[CV] .............. alpha=1e-06, hidden_layer_sizes=400, total=   2.8s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=   4.9s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200) ......................\n",
      "[CV] ....... alpha=1e-06, hidden_layer_sizes=(400, 200), total=   3.5s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=   5.4s\n",
      "[CV] alpha=1e-06, hidden_layer_sizes=(400, 200, 100) .................\n",
      "[CV] .. alpha=1e-06, hidden_layer_sizes=(400, 200, 100), total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (400, 200)}\n",
      "0.7114285714285714\n"
     ]
    }
   ],
   "source": [
    "# Set up the parameter grid to seaerch\n",
    "param_grid = [\n",
    "               {'hidden_layer_sizes': [(400), (400, 200), (400, 200, 100)], \n",
    "               'alpha': list(10.0 ** -np.arange(1, 7))}\n",
    "]\n",
    "\n",
    "# Perform the search\n",
    "my_tuned_model = GridSearchCV(neural_network.MLPClassifier(), param_grid, cv=cv_folds, verbose = 2)\n",
    "my_tuned_model.fit(X_train_plus_valid, y_train_plus_valid)\n",
    "\n",
    "# Print details\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(my_tuned_model.best_params_)\n",
    "model_tuned_params_list[\"Tuned MLP\"] = my_tuned_model.best_params_\n",
    "print(my_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7272222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.81      0.75       191\n",
      "          1       0.87      0.90      0.89       191\n",
      "          2       0.58      0.61      0.59       194\n",
      "          3       0.74      0.62      0.67       183\n",
      "          4       0.58      0.62      0.60       165\n",
      "          5       0.75      0.85      0.80       177\n",
      "          6       0.48      0.45      0.47       171\n",
      "          7       0.88      0.81      0.85       183\n",
      "          8       0.92      0.78      0.84       152\n",
      "          9       0.81      0.80      0.81       193\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1800\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>8</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>219</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>153</td>\n",
       "      <td>176</td>\n",
       "      <td>202</td>\n",
       "      <td>160</td>\n",
       "      <td>169</td>\n",
       "      <td>130</td>\n",
       "      <td>189</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1    2    3    4    5    6    7    8    9   All\n",
       "True                                                             \n",
       "0          154    5    8    8    5    3    7    0    1    0   191\n",
       "1            3  172    1   11    1    0    3    0    0    0   191\n",
       "2            4    2  118    4   30    0   31    0    0    5   194\n",
       "3           23   17    6  113   12    3    7    0    0    2   183\n",
       "4            1    0   30    7  102    0   25    0    0    0   165\n",
       "5            1    0    2    1    0  151    2   10    1    9   177\n",
       "6           31    1   30    6   21    0   77    0    4    1   171\n",
       "7            0    0    0    0    1   22    0  149    1   10   183\n",
       "8            2    0    2    2    3    6    4    6  119    8   152\n",
       "9            0    0    8    1    1   17    4    4    4  154   193\n",
       "All        219  197  205  153  176  202  160  169  130  189  1800"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_tuned_model.predict(X_test)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) # , normalize=True, sample_weight=None\n",
    "model_test_accuracy_comparisons[\"Tuned MLP\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(y_test), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Better Tree': 0.5811111111111111,\n",
       " 'Simple Tree': 0.6016666666666667,\n",
       " 'Tuned AdaBoost': 0.6188888888888889,\n",
       " 'Tuned Bagging': 0.5727777777777778,\n",
       " 'Tuned Logistic Regression': 0.6277777777777778,\n",
       " 'Tuned MLP': 0.7272222222222222,\n",
       " 'Tuned Random Forest': 0.645,\n",
       " 'Tuned Tree': 0.5794444444444444,\n",
       " 'Tuned kNN': 0.6933333333333334}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_test_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAD8CAYAAABevCxMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGSdvMzOznHHyNjMzyxknbzMzs5z5/6tNbCrvfibaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.values()), align='center')\n",
    "_ = plt.yticks(range(len(model_test_accuracy_comparisons)), list(model_test_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AdaBoost': 0.42916666666666664,\n",
       " 'Bagging': 0.6425,\n",
       " 'Better Tree': 0.6008333333333333,\n",
       " 'Logistic Regression': 0.6625,\n",
       " 'MLP': 0.7275,\n",
       " 'Random Forest': 0.63,\n",
       " 'Simple Tree': 0.6491666666666667,\n",
       " 'kNN': 0.7233333333333334}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(model_valid_accuracy_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAD8CAYAAAD61pSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCVJ6sDAlCSpAwNTkqQO/j8clkWhOlmzVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(0, 1.0)\n",
    "_ = plt.barh(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.values()), align='center')\n",
    "_= plt.yticks(range(len(model_valid_accuracy_comparisons)), list(model_valid_accuracy_comparisons.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test Best Model On Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       8    ...          103        87        56         0         0   \n",
       "1       0    ...           34         0         0         0         0   \n",
       "2      99    ...            0         0         0         0        63   \n",
       "3       0    ...          137       126       140         0       133   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2        53        31         0         0         0  \n",
       "3       224       222        56         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv('fashion-mnist_test.csv')\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_dataset[test_dataset.columns[1:]]\n",
    "test_Y = np.array(test_dataset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_filled</th>\n",
       "      <th>percent_filled_top</th>\n",
       "      <th>percent_filled_bottom</th>\n",
       "      <th>row_sum_0</th>\n",
       "      <th>row_sum_1</th>\n",
       "      <th>row_sum_2</th>\n",
       "      <th>row_sum_3</th>\n",
       "      <th>row_sum_4</th>\n",
       "      <th>row_sum_5</th>\n",
       "      <th>row_sum_6</th>\n",
       "      <th>...</th>\n",
       "      <th>row_sum_19</th>\n",
       "      <th>row_sum_20</th>\n",
       "      <th>row_sum_21</th>\n",
       "      <th>row_sum_22</th>\n",
       "      <th>row_sum_23</th>\n",
       "      <th>row_sum_24</th>\n",
       "      <th>row_sum_25</th>\n",
       "      <th>row_sum_26</th>\n",
       "      <th>row_sum_27</th>\n",
       "      <th>symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399620</td>\n",
       "      <td>0.422389</td>\n",
       "      <td>0.376851</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>0.078992</td>\n",
       "      <td>0.185994</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.550840</td>\n",
       "      <td>0.540196</td>\n",
       "      <td>0.518347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.391737</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>0.395938</td>\n",
       "      <td>0.400560</td>\n",
       "      <td>0.393697</td>\n",
       "      <td>0.370728</td>\n",
       "      <td>0.457843</td>\n",
       "      <td>0.212745</td>\n",
       "      <td>0.323980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210664</td>\n",
       "      <td>0.236134</td>\n",
       "      <td>0.185194</td>\n",
       "      <td>0.209664</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.291877</td>\n",
       "      <td>0.267787</td>\n",
       "      <td>0.248880</td>\n",
       "      <td>0.240756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199160</td>\n",
       "      <td>0.201821</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.202941</td>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.191317</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.155742</td>\n",
       "      <td>0.168367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168382</td>\n",
       "      <td>0.193377</td>\n",
       "      <td>0.143387</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.157563</td>\n",
       "      <td>0.267507</td>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.192577</td>\n",
       "      <td>0.219328</td>\n",
       "      <td>0.205462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211345</td>\n",
       "      <td>0.240196</td>\n",
       "      <td>0.157423</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.113165</td>\n",
       "      <td>0.079272</td>\n",
       "      <td>0.072129</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.038375</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.407893</td>\n",
       "      <td>0.460554</td>\n",
       "      <td>0.355232</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.455602</td>\n",
       "      <td>0.452101</td>\n",
       "      <td>0.430532</td>\n",
       "      <td>0.433053</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.500560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374510</td>\n",
       "      <td>0.319888</td>\n",
       "      <td>0.264146</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.277311</td>\n",
       "      <td>0.257423</td>\n",
       "      <td>0.475070</td>\n",
       "      <td>0.725350</td>\n",
       "      <td>0.445798</td>\n",
       "      <td>0.206633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252716</td>\n",
       "      <td>0.325090</td>\n",
       "      <td>0.180342</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.281092</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.369328</td>\n",
       "      <td>0.381933</td>\n",
       "      <td>0.343277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251261</td>\n",
       "      <td>0.259664</td>\n",
       "      <td>0.216527</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.016387</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.158163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.270638</td>\n",
       "      <td>0.251210</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>0.047479</td>\n",
       "      <td>0.181513</td>\n",
       "      <td>0.237255</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.228011</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271849</td>\n",
       "      <td>0.238515</td>\n",
       "      <td>0.256162</td>\n",
       "      <td>0.267647</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.298599</td>\n",
       "      <td>0.286975</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.404432</td>\n",
       "      <td>0.368958</td>\n",
       "      <td>0.439906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780532</td>\n",
       "      <td>0.792997</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.290756</td>\n",
       "      <td>0.255282</td>\n",
       "      <td>0.326230</td>\n",
       "      <td>0.045238</td>\n",
       "      <td>0.160784</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>0.185854</td>\n",
       "      <td>0.223389</td>\n",
       "      <td>0.243417</td>\n",
       "      <td>0.255462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346359</td>\n",
       "      <td>0.344398</td>\n",
       "      <td>0.332773</td>\n",
       "      <td>0.324790</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.280532</td>\n",
       "      <td>0.261485</td>\n",
       "      <td>0.311204</td>\n",
       "      <td>0.283193</td>\n",
       "      <td>0.104592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.167462</td>\n",
       "      <td>0.139776</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.163165</td>\n",
       "      <td>0.316947</td>\n",
       "      <td>0.357843</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124790</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.178011</td>\n",
       "      <td>0.339916</td>\n",
       "      <td>0.399860</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.176331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.215581</td>\n",
       "      <td>0.257233</td>\n",
       "      <td>0.173930</td>\n",
       "      <td>0.046218</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>0.248319</td>\n",
       "      <td>0.227731</td>\n",
       "      <td>0.203221</td>\n",
       "      <td>0.267227</td>\n",
       "      <td>0.389776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175350</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>0.176611</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>0.190616</td>\n",
       "      <td>0.192297</td>\n",
       "      <td>0.224090</td>\n",
       "      <td>0.107423</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   percent_filled  percent_filled_top  percent_filled_bottom  row_sum_0  \\\n",
       "0        0.399620            0.422389               0.376851   0.018347   \n",
       "1        0.210664            0.236134               0.185194   0.209664   \n",
       "2        0.168382            0.193377               0.143387   0.051961   \n",
       "3        0.407893            0.460554               0.355232   0.257143   \n",
       "4        0.252716            0.325090               0.180342   0.007563   \n",
       "5        0.270638            0.251210               0.290066   0.047479   \n",
       "6        0.404432            0.368958               0.439906   0.000000   \n",
       "7        0.290756            0.255282               0.326230   0.045238   \n",
       "8        0.167462            0.139776               0.195148   0.000000   \n",
       "9        0.215581            0.257233               0.173930   0.046218   \n",
       "\n",
       "   row_sum_1  row_sum_2  row_sum_3  row_sum_4  row_sum_5  row_sum_6    ...     \\\n",
       "0   0.078992   0.185994   0.414286   0.550840   0.540196   0.518347    ...      \n",
       "1   0.250000   0.267647   0.291877   0.267787   0.248880   0.240756    ...      \n",
       "2   0.157563   0.267507   0.189076   0.192577   0.219328   0.205462    ...      \n",
       "3   0.455602   0.452101   0.430532   0.433053   0.462465   0.500560    ...      \n",
       "4   0.281092   0.360924   0.362745   0.369328   0.381933   0.343277    ...      \n",
       "5   0.181513   0.237255   0.223389   0.230952   0.228011   0.247899    ...      \n",
       "6   0.000000   0.000000   0.000000   0.000000   0.000000   0.395098    ...      \n",
       "7   0.160784   0.236835   0.185854   0.223389   0.243417   0.255462    ...      \n",
       "8   0.030952   0.163165   0.316947   0.357843   0.205042   0.085294    ...      \n",
       "9   0.245238   0.248319   0.227731   0.203221   0.267227   0.389776    ...      \n",
       "\n",
       "   row_sum_19  row_sum_20  row_sum_21  row_sum_22  row_sum_23  row_sum_24  \\\n",
       "0    0.388235    0.391737    0.395098    0.395938    0.400560    0.393697   \n",
       "1    0.199160    0.201821    0.199860    0.202941    0.198039    0.191317   \n",
       "2    0.211345    0.240196    0.157423    0.139216    0.113165    0.079272   \n",
       "3    0.374510    0.319888    0.264146    0.236835    0.277311    0.257423   \n",
       "4    0.251261    0.259664    0.216527    0.034594    0.026751    0.017647   \n",
       "5    0.271849    0.238515    0.256162    0.267647    0.272829    0.282353   \n",
       "6    0.780532    0.792997    0.885714    0.123950    0.000000    0.000000   \n",
       "7    0.346359    0.344398    0.332773    0.324790    0.347059    0.280532   \n",
       "8    0.124790    0.178571    0.183333    0.178011    0.339916    0.399860   \n",
       "9    0.175350    0.173389    0.176611    0.185014    0.180952    0.190616   \n",
       "\n",
       "   row_sum_25  row_sum_26  row_sum_27  symmetry  \n",
       "0    0.370728    0.457843    0.212745  0.323980  \n",
       "1    0.185294    0.185294    0.155742  0.168367  \n",
       "2    0.072129    0.028291    0.038375  0.020408  \n",
       "3    0.475070    0.725350    0.445798  0.206633  \n",
       "4    0.016387    0.010364    0.010364  0.158163  \n",
       "5    0.298599    0.286975    0.188375  0.020408  \n",
       "6    0.000000    0.000000    0.000000  0.405612  \n",
       "7    0.261485    0.311204    0.283193  0.104592  \n",
       "8    0.423249    0.176331    0.000000  0.066327  \n",
       "9    0.192297    0.224090    0.107423  0.000000  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "engineered_features_test = pd.DataFrame()\n",
    "\n",
    "# Calcualte percentage of filled pixels and a top and bottom half only version\n",
    "percent_filled = test_X.sum(axis = 1)/(28*28)\n",
    "percent_filled_top = test_X.iloc[:, 0:392].sum(axis = 1)/(28*14)\n",
    "percent_filled_bottom = test_X.iloc[:, 392:784].sum(axis = 1)/(28*14)\n",
    "engineered_features_test['percent_filled'] = percent_filled\n",
    "engineered_features_test['percent_filled_top'] = percent_filled_top\n",
    "engineered_features_test['percent_filled_bottom'] = percent_filled_bottom\n",
    "\n",
    "# Calculate the sum of each row\n",
    "for idx, i in enumerate(range(0, 784, 28)):\n",
    "    row_sum = test_X.iloc[:, i:(i + 28)].sum(axis = 1)/28\n",
    "    engineered_features_test[\"row_sum_\" + str(idx)] = row_sum\n",
    "\n",
    "# Calcualte a measure of syymmetry around a horizontal axis\n",
    "s1 = np.round(np.array(test_X.iloc[:, 0:392]))\n",
    "s2 = np.round(np.array(test_X.iloc[:, 784:391:-1]))\n",
    "s3 = np.logical_and(s1, s2).astype(int)\n",
    "symmetry = s3.sum(axis = 1)/(28*14)\n",
    "\n",
    "engineered_features_test['symmetry'] = symmetry\n",
    "\n",
    "display(engineered_features_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = engineered_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = neural_network.MLPClassifier(hidden_layer_sizes=(400, 200))\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7535\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.74      0.72      1000\n",
      "          1       0.91      0.92      0.92      1000\n",
      "          2       0.66      0.58      0.62      1000\n",
      "          3       0.74      0.70      0.72      1000\n",
      "          4       0.67      0.66      0.66      1000\n",
      "          5       0.81      0.83      0.82      1000\n",
      "          6       0.48      0.54      0.51      1000\n",
      "          7       0.84      0.86      0.85      1000\n",
      "          8       0.93      0.85      0.89      1000\n",
      "          9       0.84      0.84      0.84      1000\n",
      "\n",
      "avg / total       0.76      0.75      0.75     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>922</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>585</td>\n",
       "      <td>19</td>\n",
       "      <td>170</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>23</td>\n",
       "      <td>700</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>43</td>\n",
       "      <td>662</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>835</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>169</td>\n",
       "      <td>9</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>538</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>864</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>846</td>\n",
       "      <td>31</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>839</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1060</td>\n",
       "      <td>1015</td>\n",
       "      <td>890</td>\n",
       "      <td>950</td>\n",
       "      <td>992</td>\n",
       "      <td>1033</td>\n",
       "      <td>1123</td>\n",
       "      <td>1024</td>\n",
       "      <td>910</td>\n",
       "      <td>1003</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1    2    3    4     5     6     7    8     9    All\n",
       "True                                                                    \n",
       "0           744     9   28   75   13    11   101     2   16     1   1000\n",
       "1            15   922   10   42    5     1     5     0    0     0   1000\n",
       "2            26     2  585   19  170     6   170     0    6    16   1000\n",
       "3            75    69   23  700   40    17    70     1    4     1   1000\n",
       "4            11     4   98   43  662     3   172     1    3     3   1000\n",
       "5             4     0    1   13    1   835    13    83    9    41   1000\n",
       "6           169     9  118   50   88     7   538     3   12     6   1000\n",
       "7             0     0    0    0    0    68     0   864    3    65   1000\n",
       "8            15     0   21    7   10    26    32    12  846    31   1000\n",
       "9             1     0    6    1    3    59    22    58   11   839   1000\n",
       "All        1060  1015  890  950  992  1033  1123  1024  910  1003  10000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = neighbors.KNeighborsClassifier()\n",
    "my_model = my_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7106\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69      1000\n",
      "          1       0.78      0.94      0.85      1000\n",
      "          2       0.59      0.63      0.61      1000\n",
      "          3       0.63      0.66      0.64      1000\n",
      "          4       0.63      0.60      0.62      1000\n",
      "          5       0.81      0.68      0.74      1000\n",
      "          6       0.49      0.44      0.47      1000\n",
      "          7       0.80      0.83      0.81      1000\n",
      "          8       0.94      0.79      0.86      1000\n",
      "          9       0.76      0.85      0.80      1000\n",
      "\n",
      "avg / total       0.71      0.71      0.71     10000\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>689</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>945</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>631</td>\n",
       "      <td>34</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>131</td>\n",
       "      <td>28</td>\n",
       "      <td>657</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>183</td>\n",
       "      <td>65</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>677</td>\n",
       "      <td>24</td>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>163</td>\n",
       "      <td>47</td>\n",
       "      <td>140</td>\n",
       "      <td>83</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>788</td>\n",
       "      <td>65</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>847</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>992</td>\n",
       "      <td>1211</td>\n",
       "      <td>1075</td>\n",
       "      <td>1040</td>\n",
       "      <td>956</td>\n",
       "      <td>836</td>\n",
       "      <td>901</td>\n",
       "      <td>1034</td>\n",
       "      <td>841</td>\n",
       "      <td>1114</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0     1     2     3    4    5    6     7    8     9    All\n",
       "True                                                                   \n",
       "0          689    53    33    95   14    2  100     2   12     0   1000\n",
       "1            9   945     9    31    2    1    3     0    0     0   1000\n",
       "2           18    23   631    34  158    1  115     0    7    13   1000\n",
       "3           73   131    28   657   36    2   69     0    2     2   1000\n",
       "4           13    11   183    65  602    1  118     0    3     4   1000\n",
       "5           10     1     8    43    3  677   24   136    8    90   1000\n",
       "6          163    47   140    83  106    1  443     0   12     5   1000\n",
       "7            0     0     0     0    0   84    0   827    1    88   1000\n",
       "8           15     0    30    16   23   35   13    15  788    65   1000\n",
       "9            2     0    13    16   12   32   16    54    8   847   1000\n",
       "All        992  1211  1075  1040  956  836  901  1034  841  1114  10000"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = my_model.predict(test_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_Y, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_Y, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(np.array(test_Y), y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hence we see that we get the best accuracy for the Engineered model when we use MLP with the prams obtained during the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
